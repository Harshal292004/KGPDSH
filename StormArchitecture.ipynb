{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLr8xUZqtrC7JOXkgNI9EY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harshal292004/KGPDSH/blob/master/StormArchitecture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6dFPfVFZwx5",
        "outputId": "a27ab605-ccd0-449b-9cff-b72291c1a4ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-52-57665ae7619a>:18: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  @validator('score')\n",
            "<ipython-input-52-57665ae7619a>:79: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  @validator('confidence_level')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Conference: CVPR\n",
            "Justification: This paper fits the CVPR conference themes as it focuses on 3D vision and pattern recognition, specifically in the application of computer vision for dietary oversight and nutrition tracking. The paper presents a comprehensive review of 3D food modeling techniques and introduces the MetaFood Challenge, which aims to generate precise and volumetrically accurate 3D food models from 2D images. The challenge involves 3D reconstruction methods, which aligns with the conference themes. The paper also presents encouraging outcomes in 3D food reconstruction, showing great promise for refining portion estimation in dietary evaluations and nutritional tracking. However, the paper may not have significant advances in methodology or novel contributions, which is why it scores 7.5 rather than higher. Nevertheless, it is a relevant and practical contribution to the field of computer vision.\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts.chat import ChatPromptTemplate\n",
        "from pydantic import BaseModel, Field, validator, PrivateAttr\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from google.colab import userdata\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_community.vectorstores import PathwayVectorClient\n",
        "\n",
        "import json\n",
        "import re\n",
        "from typing import List, Dict\n",
        "\n",
        "class ScoreDetails(BaseModel):\n",
        "    score: float = Field(description=\"Score of the aspect (0-10)\")\n",
        "    justification: str = Field(description=\"Explanation for the score\")\n",
        "\n",
        "    @validator('score')\n",
        "    def validate_score(cls, v: float) -> float:\n",
        "        if v < 0 or v > 10:\n",
        "            raise ValueError('Score must be between 0 and 10')\n",
        "        return round(v, 1)\n",
        "\n",
        "# Evaluation Categories\n",
        "class Significance(BaseModel):\n",
        "    theoretical_contribution: ScoreDetails = Field(description=\"Assessment of theoretical contribution to the field\")\n",
        "    practical_impact: ScoreDetails = Field(description=\"Evaluation of practical applications and real-world impact\")\n",
        "    novelty: ScoreDetails = Field(description=\"Originality of the research and its contribution\")\n",
        "\n",
        "class MethodologyEvaluation(BaseModel):\n",
        "    research_design: ScoreDetails = Field(description=\"Appropriateness and quality of research design\")\n",
        "    reproducibility: ScoreDetails = Field(description=\"Clarity and completeness of methods for reproduction\")\n",
        "\n",
        "class PresentationQuality(BaseModel):\n",
        "    writing_clarity: ScoreDetails = Field(description=\"Clarity and effectiveness of writing\")\n",
        "    organization: ScoreDetails = Field(description=\"Logical flow and structure of the paper\")\n",
        "    literature_review: ScoreDetails = Field(description=\"Comprehensiveness of literature review\")\n",
        "\n",
        "class PaperEvaluation(BaseModel):\n",
        "    paper_id: str = Field(description=\"Unique identifier for the paper\")\n",
        "    significance: Significance = Field(description=\"Evaluation of research significance\")\n",
        "    methodology: MethodologyEvaluation = Field(description=\"Detailed methodology assessment\")\n",
        "    presentation: PresentationQuality = Field(description=\"Quality of presentation\")\n",
        "    confidence_level: float = Field(description=\"Overall confidence in this review (0-10)\")\n",
        "    _overall_score: float = PrivateAttr(default=0.0)\n",
        "    major_strengths: List[str] = Field(description=\"Major strengths of the paper\")\n",
        "    major_weaknesses: List[str] = Field(description=\"Major weaknesses of the paper\")\n",
        "    detailed_feedback: str = Field(description=\"Comprehensive feedback and suggestions\")\n",
        "    summary_of_paper: str = Field(description=\"Relevant summary for retrieval tasks\")\n",
        "\n",
        "    @property\n",
        "    def overall_score(self) -> float:\n",
        "        if self._overall_score == 0.0:\n",
        "            weights = {\n",
        "                'significance': 0.3,\n",
        "                'methodology': 0.5,\n",
        "                'presentation': 0.2,\n",
        "            }\n",
        "\n",
        "            sig_score = (self.significance.theoretical_contribution.score +\n",
        "                         self.significance.practical_impact.score +\n",
        "                         self.significance.novelty.score) / 3\n",
        "\n",
        "            meth_score = (self.methodology.research_design.score +\n",
        "                          self.methodology.reproducibility.score) / 2\n",
        "\n",
        "            pres_score = (self.presentation.writing_clarity.score +\n",
        "                          self.presentation.organization.score +\n",
        "                          self.presentation.literature_review.score) / 3\n",
        "\n",
        "            self._overall_score = round(\n",
        "                weights['significance'] * sig_score +\n",
        "                weights['methodology'] * meth_score +\n",
        "                weights['presentation'] * pres_score ,\n",
        "                3\n",
        "            )\n",
        "        return self._overall_score\n",
        "\n",
        "    @validator('confidence_level')\n",
        "    def validate_confidence(cls, v: float) -> float:\n",
        "        if v < 0 or v > 10:\n",
        "            raise ValueError('Confidence level must be between 0 and 10')\n",
        "        return round(v, 1)\n",
        "\n",
        "    def generate_summary_report(self) -> str:\n",
        "        string = f\"\"\"\n",
        "        Paper Review Summary (ID: {self.paper_id})\n",
        "        ==========================================\n",
        "        Review Confidence: {self.confidence_level}/10\n",
        "        Overall Score: {self.overall_score}/10\n",
        "        Key Strengths:\n",
        "        {chr(10).join(f\"- {strength}\" for strength in self.major_strengths)}\n",
        "\n",
        "        Areas for Improvement:\n",
        "        {chr(10).join(f\"- {weakness}\" for weakness in self.major_weaknesses)}\n",
        "\n",
        "        Detailed Feedback:\n",
        "        {self.detailed_feedback}\n",
        "\n",
        "        Summary of the Paper:\n",
        "        {self.summary_of_paper}\n",
        "        \"\"\"\n",
        "        return string\n",
        "\n",
        "# Implementing STORM Architecture with LangGraph\n",
        "class ConferenceAgent:\n",
        "    def __init__(self, name: str, chat_model: ChatGroq, target_conference: str, conference_themes: str, conference_context:str):\n",
        "        self.name = name\n",
        "        self.chat_model = chat_model\n",
        "        self.target_conference = target_conference\n",
        "        self.conference_themes = conference_themes\n",
        "        self.conference_context = conference_context\n",
        "\n",
        "    def evaluate_paper(self, paper_summary: str) -> Dict:\n",
        "        prompt = ChatPromptTemplate.from_messages([\n",
        "            ('system',  f\"\"\"\n",
        "            You are a representative for the conference {self.target_conference}. Strictly Focus Specially on the conference themes: {self.conference_themes}\n",
        "            Use the following additional context to guide your evaluation:\n",
        "            {self.conference_context}\n",
        "\n",
        "            Evaluate the research paper based on:\n",
        "            - Relevance to conference themes\n",
        "            - Quality of methodology\n",
        "            - Novelty of contribution\n",
        "            Provide a score (0-10) and a justification for why the paper fits this conference.\n",
        "            Respond is json format with the following keys\n",
        "            - score: float\n",
        "            - justification: str\n",
        "            \"\"\"),\n",
        "            ('user', \"Paper summary: {paper_summary}\")\n",
        "        ])\n",
        "        chain = LLMChain(llm = self.chat_model, prompt=prompt)\n",
        "        response = chain.run({\"paper_summary\": paper_summary})\n",
        "        try:\n",
        "            # Preprocess the response to clean up invalid characters\n",
        "            cleaned_response = re.sub(r'[\\x00-\\x1F\\x7F]', '', response)  # Remove control characters\n",
        "            json_match = re.search(r'\\{.*\\}', cleaned_response, re.DOTALL)\n",
        "            if json_match:\n",
        "                json_response = json_match.group(0)\n",
        "                response_dict = json.loads(json_response)\n",
        "                return {\n",
        "                    \"score\": float(response_dict[\"score\"]),\n",
        "                    \"justification\": response_dict[\"justification\"],\n",
        "                }\n",
        "            else:\n",
        "                raise ValueError(f\"No JSON object found in the response: {response}\")\n",
        "        except json.JSONDecodeError as e:\n",
        "            raise ValueError(f\"Failed to parse response as JSON: {response}\") from e\n",
        "\n",
        "class STORMSystem:\n",
        "    def __init__(self, agents: List[ConferenceAgent]):\n",
        "        self.agents = agents\n",
        "\n",
        "    def discuss_and_decide(self, paper_summary: str) -> Dict:\n",
        "        evaluations = []\n",
        "        for agent in self.agents:\n",
        "            evaluation = agent.evaluate_paper(paper_summary)\n",
        "            evaluations.append({\n",
        "                \"conference\": agent.target_conference,\n",
        "                \"score\": evaluation[\"score\"],\n",
        "                \"justification\": evaluation[\"justification\"],\n",
        "            })\n",
        "\n",
        "        # Determine the best conference based on scores\n",
        "        best_conference = max(evaluations, key=lambda x: x[\"score\"])\n",
        "        return {\n",
        "            \"best_conference\": best_conference[\"conference\"],\n",
        "            \"justification\": best_conference[\"justification\"],\n",
        "        }\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    chat_model = ChatGroq(groq_api_key = userdata.get(\"GROQ_API_KEY\").strip(), model=\"llama3-8b-8192\")\n",
        "\n",
        "    # Define agents for each conference\n",
        "    agents = [\n",
        "        ConferenceAgent(name=\"Agent CVPR\", chat_model=chat_model, target_conference=\"CVPR\",\n",
        "                        conference_themes = \"\"\"\n",
        "                        CVPR focuses on the field of computer vision, image processing, and pattern recognition. Key themes include:\n",
        "                          Object detection and recognition.\n",
        "                          Image segmentation and scene understanding.\n",
        "                          Visual tracking and motion analysis.\n",
        "                          3D vision, stereo vision, and depth estimation.\n",
        "                          Deep learning for vision tasks (CNNs, Vision Transformers, etc.).\n",
        "                          Applications in medical imaging, autonomous vehicles, and robotics.\n",
        "                          Video processing and understanding.\n",
        "                          Computational photography and imaging.\n",
        "                          Low-level vision (denoising, super-resolution).\n",
        "                          Vision-based augmented reality and virtual reality.\n",
        "                        \"\"\",\n",
        "                        conference_context = \"\"\"\n",
        "                        Examples of accepted papers:\n",
        "                          - YOLO: Real-Time Object Detection\n",
        "                              Summary: Proposes an efficient deep learning model for real-time object detection with state-of-the-art accuracy.\n",
        "                          - SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation\n",
        "                              Summary: Focuses on pixel-wise image segmentation using deep neural networks, with applications in autonomous systems.\n",
        "                          - 3D Object Detection and Localization Using RGB and Depth Data\n",
        "                              Summary: Combines RGB and depth information for accurate 3D object detection in indoor environments.\n",
        "                        Evaluation Criteria:\n",
        "                         - Relevance to core computer vision topics.\n",
        "                         - Advances in methodology or application.\n",
        "                         - Practical implications for industries like healthcare, robotics, and transportation.\n",
        "                        \"\"\"\n",
        "                        ),\n",
        "        ConferenceAgent(name=\"Agent NeurIPS\", chat_model=chat_model, target_conference=\"NeurIPS\"\n",
        "                        ,conference_themes =\"\"\"\n",
        "                        NeurIPS emphasizes machine learning, computational neuroscience, and AI-related topics. Key themes include:\n",
        "                            Deep learning (e.g., architectures, generative models, optimization for deep networks, foundation models, LLMs)\n",
        "                            Reinforcement learning and decision-making.\n",
        "                            Probabilistic models and Bayesian learning.\n",
        "                            Optimization techniques for machine learning.\n",
        "                            Representation learning and embeddings.\n",
        "                            AI for healthcare, climate science, and sustainability.\n",
        "                            Neuroscience-inspired algorithms and theories.\n",
        "                            Ethical AI, fairness, and explainability.\n",
        "                        \"\"\",\n",
        "                        conference_context = \"\"\"\n",
        "                        Examples of accepted papers:\n",
        "                          - Attention Is All You Need\n",
        "                             Summary: Introduces the transformer architecture, which revolutionized NLP and other domains by using self-attention mechanisms.\n",
        "                          - Generative Adversarial Networks (GANs)\n",
        "                             Summary: Proposes a novel framework for training generative models using adversarial networks.\n",
        "                          - Adam: A Method for Stochastic Optimization\n",
        "                             Summary: Proposes a new optimization algorithm that balances convergence speed and stability in deep learning.\n",
        "                        Evaluation Criteria:\n",
        "                          - Novelty and theoretical contributions.\n",
        "                          - Experimental rigor and reproducibility.\n",
        "                          - Broader implications for machine learning and interdisciplinary applications.\n",
        "                        \"\"\"\n",
        "        ),\n",
        "        ConferenceAgent(name=\"Agent EMNLP\", chat_model=chat_model, target_conference=\"EMNLP\"\n",
        "                        ,conference_themes = \"\"\"\n",
        "                        EMNLP specializes in NLP and computational linguistics. Key themes include:\n",
        "                          Machine translation and cross-lingual NLP.\n",
        "                          Large language models and foundational models.\n",
        "                          Sentiment analysis and opinion mining.\n",
        "                          Dialogue systems and conversational AI.\n",
        "                          Question answering and information retrieval.\n",
        "                          Text summarization and abstraction.\n",
        "                          Morphology, syntax, and semantics.\n",
        "                          Multimodal NLP (text + image/audio fusion).\n",
        "                          Ethical concerns in NLP (bias, toxicity detection).\n",
        "                          Low-resource and multilingual NLP.\n",
        "                        \"\"\",\n",
        "                        conference_context = \"\"\"\n",
        "                        Examples of accepted papers:\n",
        "\n",
        "Paper Title: Pre-trained Language Models for Text-to-Text Generation\n",
        "Summary: This paper explores pre-trained models (e.g., T5) for a variety of text-to-text NLP tasks, showcasing improvements across summarization, question answering, and translation.\n",
        "\n",
        "Paper Title: Adversarial Training for Robust Text Classification\n",
        "Summary: Proposes an adversarial training framework that enhances the robustness of text classification models against noisy and adversarial inputs.\n",
        "\n",
        "Paper Title: Knowledge-Enhanced Contextual Representations for Entity Linking\n",
        "Summary: Combines external knowledge sources with contextual embeddings to improve entity linking in complex domains.\n",
        "\n",
        "Paper Title: Multimodal Sentiment Analysis with Attention Mechanisms\n",
        "Summary: Introduces a framework for combining visual and textual inputs to improve sentiment detection in videos.\n",
        "\n",
        "Evaluation Criteria:\n",
        "Relevance to NLP:\n",
        "\n",
        "Papers should directly address core NLP tasks, methodologies, or applications.\n",
        "Emphasis on empirical evaluation and innovation in language processing methods.\n",
        "Quality of Methodology:\n",
        "\n",
        "Rigorous experiments, proper baselines, and thorough ablation studies.\n",
        "Use of diverse and large-scale datasets to validate results.\n",
        "Novelty of Contribution:\n",
        "\n",
        "New architectures, algorithms, or findings that advance the field.\n",
        "Extensions of existing methods to novel tasks or domains.\n",
        "Broader Impacts:\n",
        "\n",
        "Ethical implications of the research (e.g., bias in models, data privacy).\n",
        "Potential for cross-disciplinary applications (e.g., in healthcare, education, or social media).\n",
        "Themes Breakdown with Examples:\n",
        "Natural Language Understanding:\n",
        "\n",
        "Semantic role labeling, coreference resolution, and discourse parsing.\n",
        "Example: A New Framework for Semantic Parsing Using Pre-Trained Transformers.\n",
        "Language Generation:\n",
        "\n",
        "Dialogue systems, machine translation, and creative text generation.\n",
        "Example: Controlled Text Generation with Discrete and Continuous Latent Variables.\n",
        "Information Extraction:\n",
        "\n",
        "Named entity recognition, relation extraction, and knowledge graph construction.\n",
        "Example: Joint Entity and Relation Extraction with Transformer-Based Models.\n",
        "Multimodal NLP:\n",
        "\n",
        "Integrating vision, audio, and textual modalities.\n",
        "Example: Aligning Text and Vision for Multimodal Machine Translation.\n",
        "Social and Ethical Considerations:\n",
        "\n",
        "Bias, fairness, interpretability, and environmental impacts of NLP models.\n",
        "Example: Bias Mitigation in Pre-trained Models: A Data Augmentation Approach.\n",
        "\n",
        "                        \"\"\"\n",
        "\n",
        "        ),\n",
        "        ConferenceAgent(name=\"Agent KDD\", chat_model=chat_model, target_conference=\"KDD\"\n",
        "                        ,conference_themes = \"\"\"\n",
        "                        KDD centers on data mining, big data, and applied AI. Key themes include:\n",
        "                            Scalable data mining algorithms.\n",
        "                            Graph data and network analysis.\n",
        "                            Temporal and sequential data mining.\n",
        "                            Anomaly detection and predictive modeling.\n",
        "                            Recommender systems and personalization.\n",
        "                            Causal inference and counterfactual reasoning.\n",
        "                            Applications in finance, e-commerce, and marketing.\n",
        "                            Data visualization and interpretability.\n",
        "                            Data ethics and privacy-preserving techniques.\n",
        "                            AI and data-driven solutions for social good.\n",
        "                        \"\"\",\n",
        "\n",
        "                        conference_context=\"\"\"\n",
        "                        Examples of accepted papers:\n",
        "\n",
        "Paper Title: Scalable Graph Neural Networks for Large-Scale Social Network Analysis\n",
        "Summary: Introduces a scalable GNN framework that handles billion-scale graphs with high efficiency, showcasing applications in social network analysis.\n",
        "\n",
        "Paper Title: Causal Discovery in High-Dimensional Data Using Deep Learning\n",
        "Summary: Proposes a deep learning-based approach for identifying causal relationships in high-dimensional data.\n",
        "\n",
        "Paper Title: Fair Representation Learning with Adversarial Networks\n",
        "Summary: Develops a framework for learning fair data representations while minimizing demographic bias in downstream tasks.\n",
        "\n",
        "Paper Title: Adaptive Online Learning for Real-Time Recommender Systems\n",
        "Summary: Presents an adaptive online learning algorithm that updates recommender system models in real time based on user interactions.\n",
        "\n",
        "Evaluation Criteria:\n",
        "Relevance to Knowledge Discovery and Data Mining:\n",
        "\n",
        "Papers must address core challenges in data mining, machine learning, or related applications.\n",
        "Emphasis on practical applications and scalability to real-world data.\n",
        "Methodological Rigor:\n",
        "\n",
        "Strong theoretical foundations or innovative empirical methodologies.\n",
        "Comprehensive experiments with real-world datasets and benchmarks.\n",
        "Scalability and Efficiency:\n",
        "\n",
        "Solutions must handle large-scale data effectively, both in computation and memory.\n",
        "Novelty and Impact:\n",
        "\n",
        "New techniques, algorithms, or applications that significantly advance the state-of-the-art.\n",
        "Real-world relevance and potential societal or economic impact.\n",
        "Broader Implications:\n",
        "\n",
        "Ethical considerations, such as fairness, transparency, and responsible use of data.\n",
        "Long-term applicability across industries and domains.\n",
        "                        \"\"\"\n",
        "        ),\n",
        "    ]\n",
        "\n",
        "    storm_system = STORMSystem(agents=agents)\n",
        "\n",
        "    # Input a research paper summary\n",
        "    paper_summary = \"\"\"\n",
        "    Advancements in 3D Food Modeling: A Review of the\n",
        "MetaFood Challenge Techniques and Outcomes\n",
        "The growing focus on leveraging computer vision for dietary oversight and nutri-\n",
        "tion tracking has spurred the creation of sophisticated 3D reconstruction methods\n",
        "\n",
        "for food. The lack of comprehensive, high-fidelity data, coupled with limited\n",
        "collaborative efforts between academic and industrial sectors, has significantly\n",
        "hindered advancements in this domain. This study addresses these obstacles by\n",
        "introducing the MetaFood Challenge, aimed at generating precise, volumetrically\n",
        "\n",
        "accurate 3D food models from 2D images, utilizing a checkerboard for size cal-\n",
        "ibration. The challenge was structured around 20 food items across three levels\n",
        "\n",
        "of complexity: easy (200 images), medium (30 images), and hard (1 image). A\n",
        "total of 16 teams participated in the final assessment phase. The methodologies\n",
        "developed during this challenge have yielded highly encouraging outcomes in\n",
        "3D food reconstruction, showing great promise for refining portion estimation in\n",
        "dietary evaluations and nutritional tracking. Further information on this workshop\n",
        "challenge and the dataset is accessible via the provided URL.\n",
        "    \"\"\"\n",
        "    decision = storm_system.discuss_and_decide(paper_summary)\n",
        "    print(f\"Best Conference: {decision['best_conference']}\")\n",
        "    print(f\"Justification: {decision['justification']}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain langchain_community langgraph langchain_groq langchain_huggingface pathway"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZ76QDxNzI2L",
        "outputId": "d32010d3-316f-43f8-c141-84ec3757be0a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.14)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.3.14)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.10/dist-packages (0.2.61)\n",
            "Requirement already satisfied: langchain_groq in /usr/local/lib/python3.10/dist-packages (0.2.2)\n",
            "Requirement already satisfied: langchain_huggingface in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: pathway in /usr/local/lib/python3.10/dist-packages (0.16.3)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pathway_client (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pathway_client\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade langgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCvMvqsQzRVv",
        "outputId": "5c6f10c6-0f6a-45da-c0a6-5f96c2a564fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.10/dist-packages (0.2.61)\n",
            "Requirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in /usr/local/lib/python3.10/dist-packages (from langgraph) (0.3.29)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from langgraph) (2.0.9)\n",
            "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /usr/local/lib/python3.10/dist-packages (from langgraph) (0.1.48)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.33)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.2.3)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (24.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.10.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (4.12.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.4->langgraph) (1.1.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.10/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.12)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.2.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pathway connector\n",
        "from langchain_community.vectorstores import PathwayVectorClient\n",
        "\n",
        "client = PathwayVectorClient(url=\"https://demo-document-indexing.pathway.stream\")\n"
      ],
      "metadata": {
        "id": "bQ8yAHhz1Kd4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is Pathway?\"\n",
        "docs = client.similarity_search(query, timeout=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYRycdCSOYxR",
        "outputId": "49aa1719-8fcd-4249-a2fb-8e098a7bb337"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Unknown kwargs passed to PathwayVectorClient.similarity_search: {'timeout': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "YFJ8abidOtbb",
        "outputId": "25ed5e92-0eba-4c4b-aef8-7fde1f64ad59"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3 2 0 2\\nl u J\\n2 1\\n]\\nG L . s c [\\n1 v 6 1 1 3 1 . 7 0 3 2 : v i X r a\\nPathway: a fast and flexible unified stream data processing framework for analytical and Machine Learning applications\\nMichał Bartoszkiewicz\\nJan Chorowski∗\\nAdrian Kosowski\\nJakub Kowalski\\nSergey Kulik\\nMateusz Lewandowski\\nKrzysztof Nowicki\\nKamil Piechowiak\\nOlivier Ruas\\nZuzanna Stamirowska\\nPrzemysław Uznański\\n{firstname.lastname}@pathway.com Pathway.com Paris, France\\nABSTRACT We present Pathway, a new unified data processing framework that can run workloads on both bounded and unbounded data streams. The framework was created with the original motivation of re- solving challenges faced when analyzing and processing data from the physical economy, including streams of data generated by IoT and enterprise systems. These required rapid reaction while calling for the application of advanced computation paradigms (machine- learning-powered analytics, contextual analysis, and other elements of complex event processing). Pathway is equipped with a Table API tailored for Python and Python/SQL workflows, and is pow- ered by a distributed incremental dataflow in Rust. We describe the system and present benchmarking results which demonstrate its capabilities in both batch and streaming contexts, where it is able to surpass state-of-the-art industry frameworks in both scenarios. We also discuss streaming use cases handled by Pathway which cannot be easily resolved with state-of-the-art industry frameworks, such as streaming iterative graph algorithms (PageRank, etc.).\\nCCS CONCEPTS • Information systems → Computing platforms; Data stream- ing; Location based services.\\nKEYWORDS Event streaming, Batch computation, Incremental computation, Pathway, Benchmark.\\n1 INTRODUCTION Traditionally, data processing systems were designed either for high throughput batch computations, or for low latency streaming processing. However, modern data applications often demand low latencies at high data throughputs. One solution is the lambda architecture [20], which calls for running two similar workloads: a batch one for exact computations on historical data and a streaming one used to patch the batch results with latest data. Alternatively, aiming to avoid architecture complexity, it is also possible to rely on data processing frameworks which unify batch and streaming computations.\\nThe new data processing framework which we describe in this paper, Pathway, has a unified runtime suitable for running both streaming and batch tasks. Its design results from the need to per- form certain types of real-time analytics workloads, which we con- sidered in the logistics and supply chain vertical (see Section 2) but arguably representative of a wider range of industry data. These workloads call for a contextual data analysis, sometimes entering into the real-time machine learning space, in addition to giving significant attention to out-of-order data point arrival in event streams. They also typically require the reconciliation of numerous event streams, some of which may carry contradictory (erroneous) information.\\nPathway is a data processing framework with a Python API and a reactive data processing engine with a tunable batch size which allows it to be dynamically adjusted for a desired throughput vs latency trade-off. In this paper, we describe its features and pro- vide benchmark results, comparing Pathway to leading batch and streaming data processing systems on a classical analytical bench- mark, namely a word counting task implemented using groupby, and a fundamental iterative graph processing algorithm, namely PageRank. We demonstrate that Pathway is capable of achieving throughput outperforming state-of-the-art general purpose batch engines, while being able to respond with latencies better than state- of-the-art streaming systems. At the same time, Pathway succeeds in handling in streaming mode types of iterative and contextual workloads, such as PageRank on a changing graph, which to our knowledge are not supported by any generally industrialized system with a Dataframe/Table API programming layer. Overall, the system performance is owed to a combination of design choices around mapping between tabular syntax and actual key-value data orga- nization, the performance of the underlying differential dataflow assembly for key-value data, the designed operator primitives, and inter-operator optimizations made in the transpilation process.\\nThe paper is structured as follows. In Section 2, we outline the original motivation for the creation of Pathway originating from industry use cases. In Section 3, we provide a historical overview of some of the major approaches to dataflow-based streaming data processing. An overview of the Pathway framework, together with code examples, is put forward in Section 4. In Section 5 we provide\\n∗Authors in alphabetical order. Corresponding author: jan.chorowski@pathway.com.\\nPathway team\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from pathway.xpacks.llm.vector_store import VectorStoreServer\n",
        "import os\n",
        "\n",
        "os.environ['HF_TOKEN'] = userdata.get(\"HF_TOKEN\")\n",
        "\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "embeddings = HuggingFaceEmbeddings(model_name='all-MiniLM-L6-v2')\n",
        "\n",
        "\n",
        "import pathway as pw\n",
        "\n",
        "# Example data for table creation\n",
        "data = [\n",
        "    {\"text\": \"This is a test justification.\", \"id\": \"1\"},\n",
        "    {\"text\": \"Another piece of text.\", \"id\": \"2\"}\n",
        "]\n",
        "\n",
        "try:\n",
        "    # Create a Pathway table from records\n",
        "    pathway_table = pw.Table.from_records(\n",
        "        data,\n",
        "        schema=pw.Schema(columns={\n",
        "            \"text\": pw.Column(type=str),\n",
        "            \"id\": pw.Column(type=str)\n",
        "        })\n",
        "    )\n",
        "    print(\"Pathway Table created successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error creating Pathway Table: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0Zf0jA8PC7Q",
        "outputId": "0dd3b0c8-3778-4d6e-ada9-74d779a97ccf"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error creating Pathway Table: 'super' object has no attribute '__getattr__'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip uninstall pathway"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6DY4yjyQNww",
        "outputId": "86aa56e9-ff6b-40d2-a920-7966a0282558"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: pathway 0.16.3\n",
            "Uninstalling pathway-0.16.3:\n",
            "  Would remove:\n",
            "    /usr/local/bin/pathway\n",
            "    /usr/local/lib/python3.10/dist-packages/pathway-0.16.3.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/pathway/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled pathway-0.16.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pathway"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O42s06Y709Hp",
        "outputId": "a10d921c-9028-4b2b-e357-bb959247075d"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y\n",
            "Collecting pathway\n",
            "  Using cached pathway-0.16.3-cp310-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "Requirement already satisfied: aiohttp>=3.8.4 in /usr/local/lib/python3.10/dist-packages (from pathway) (3.11.10)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (8.1.7)\n",
            "Requirement already satisfied: geopy>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.4.1)\n",
            "Requirement already satisfied: h3>=4 in /usr/local/lib/python3.10/dist-packages (from pathway) (4.1.2)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.26.4)\n",
            "Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.6.0)\n",
            "Requirement already satisfied: shapely>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.0.6)\n",
            "Requirement already satisfied: sqlglot==10.6.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (10.6.1)\n",
            "Requirement already satisfied: pyarrow>=10.0.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (17.0.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.32.3)\n",
            "Requirement already satisfied: python-sat>=0.1.8.dev0 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.8.dev14)\n",
            "Requirement already satisfied: beartype<0.16.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (0.15.0)\n",
            "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (13.9.4)\n",
            "Requirement already satisfied: diskcache>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (5.6.3)\n",
            "Requirement already satisfied: exceptiongroup>=1.1.3 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.2.2)\n",
            "Requirement already satisfied: boto3>=1.26.76 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.35.93)\n",
            "Requirement already satisfied: google-api-python-client>=2.108.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.155.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (4.12.2)\n",
            "Requirement already satisfied: panel>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.5.4)\n",
            "Requirement already satisfied: jupyter-bokeh>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from pathway) (4.0.5)\n",
            "Requirement already satisfied: jmespath>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.0.1)\n",
            "Requirement already satisfied: aiohttp-cors>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (0.7.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.29.0)\n",
            "Requirement already satisfied: fs>=2.4.16 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.4.16)\n",
            "Requirement already satisfied: async-lru>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.0.4)\n",
            "Requirement already satisfied: networkx>=3.2.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (3.4.2)\n",
            "Requirement already satisfied: google-cloud-pubsub>=2.21.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.27.1)\n",
            "Requirement already satisfied: google-cloud-bigquery in /usr/local/lib/python3.10/dist-packages (from pathway) (3.25.0)\n",
            "Requirement already satisfied: pydantic~=2.9.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.9.2)\n",
            "Requirement already satisfied: gitpython>=3.1.43 in /usr/local/lib/python3.10/dist-packages (from pathway) (3.1.43)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway) (1.18.3)\n",
            "Requirement already satisfied: botocore<1.36.0,>=1.35.93 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.26.76->pathway) (1.35.93)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.26.76->pathway) (0.10.4)\n",
            "Requirement already satisfied: appdirs~=1.4.3 in /usr/local/lib/python3.10/dist-packages (from fs>=2.4.16->pathway) (1.4.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from fs>=2.4.16->pathway) (75.1.0)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.10/dist-packages (from fs>=2.4.16->pathway) (1.17.0)\n",
            "Requirement already satisfied: geographiclib<3,>=1.52 in /usr/local/lib/python3.10/dist-packages (from geopy>=2.4.0->pathway) (2.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython>=3.1.43->pathway) (4.0.11)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.108.0->pathway) (0.22.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.108.0->pathway) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.108.0->pathway) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.108.0->pathway) (2.19.2)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.108.0->pathway) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.51.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (1.68.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (1.25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (5.29.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (0.13.1)\n",
            "Requirement already satisfied: grpcio-status>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (1.62.3)\n",
            "Requirement already satisfied: bokeh==3.* in /usr/local/lib/python3.10/dist-packages (from jupyter-bokeh>=3.0.7->pathway) (3.6.2)\n",
            "Requirement already satisfied: ipywidgets==8.* in /usr/local/lib/python3.10/dist-packages (from jupyter-bokeh>=3.0.7->pathway) (8.1.5)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (3.1.4)\n",
            "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (1.3.1)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (24.2)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (11.0.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (6.0.2)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (6.3.3)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (2024.9.0)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (4.0.13)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (3.0.13)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.22.0->pathway) (1.2.15)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.22.0->pathway) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.22.0->pathway) (1.66.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.29.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.22.0->pathway) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.29.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.22.0->pathway) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk>=1.22.0->pathway) (0.50b0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1->pathway) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1->pathway) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1->pathway) (2024.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (6.2.0)\n",
            "Requirement already satisfied: linkify-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (2.0.3)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (3.7)\n",
            "Requirement already satisfied: markdown-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (3.0.0)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (0.4.2)\n",
            "Requirement already satisfied: param<3.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (2.2.0)\n",
            "Requirement already satisfied: pyviz-comms>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (3.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic~=2.9.0->pathway) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic~=2.9.0->pathway) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->pathway) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->pathway) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->pathway) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->pathway) (2024.12.14)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->pathway) (2.18.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->pathway) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->pathway) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->pathway) (3.5.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery->pathway) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery->pathway) (2.7.2)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api>=1.22.0->pathway) (1.17.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.43->pathway) (5.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=2.108.0->pathway) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=2.108.0->pathway) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=2.108.0->pathway) (4.9)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery->pathway) (1.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client>=2.108.0->pathway) (3.2.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.22.0->pathway) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py->panel>=1.3.1->pathway) (0.1.2)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->panel>=1.3.1->pathway) (0.5.1)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py->panel>=1.3.1->pathway) (1.0.3)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (3.0.48)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.9->bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=2.108.0->pathway) (0.6.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.2.13)\n",
            "Using cached pathway-0.16.3-cp310-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.6 MB)\n",
            "Installing collected packages: pathway\n",
            "Successfully installed pathway-0.16.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XIzatGLw1pak"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}