{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harshal292004/KGPDSH/blob/master/stormintegration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2Mzv87hb_iG",
        "outputId": "f883146e-d3a5-43ab-e9c6-3ea60a62290d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-93d76f81c402>:29: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  @validator('score')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: content='I would classify this research paper as \"Publishable\".\\n\\nHere\\'s a brief justification based on the provided criteria:\\n\\n* Methodology clarity: The paper clearly introduces a new dataset (MLB-YouTube) and describes its structure, which is well-defined and replicable. The methodology for evaluating activity recognition methods and forecasting pitch velocity and type is also clearly outlined.\\n* Coherence: The paper follows a logical structure, starting with the introduction of the dataset, followed by the evaluation of activity recognition methods, and then assessing the effectiveness of different models for forecasting pitch velocity and type.\\n* Validity: The paper provides evidence to support its findings, including the effectiveness of incorporating temporal dynamics into models for detailed activity recognition.\\n\\nThe paper appears to be well-structured, with a clear introduction, methodology, and results section. The authors provide a clear overview of the dataset and the methods used to evaluate activity recognition and forecasting. The paper also presents specific findings and conclusions, which suggests that it is a publishable research paper.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 202, 'prompt_tokens': 756, 'total_tokens': 958, 'completion_time': 0.168333333, 'prompt_time': 0.094417453, 'queue_time': 0.018922436, 'total_time': 0.262750786}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_6a6771ae9c', 'finish_reason': 'stop', 'logprobs': None} id='run-4b3b573e-2efb-4882-935d-1c2a75cf64b6-0' usage_metadata={'input_tokens': 756, 'output_tokens': 202, 'total_tokens': 958}\n",
            "Response: content='I would classify this research paper as \"Publishable\".\\n\\nHere\\'s a brief justification:\\n\\n* Methodology clarity: The paper clearly explains the methodology used to collect and annotate the dataset (MLB-YouTube) and the various methods for temporal feature aggregation. The approach is well-defined and replicable.\\n* Coherence: The paper follows a logical structure, starting with an introduction to the dataset, followed by related work in the field of activity recognition, and then presenting the methods and results.\\n* Validity: The results are justified with evidence from the dataset and comparisons with other methods in the field of activity recognition. The paper also provides a clear explanation of the limitations of the study, such as the restriction of access to the data.\\n\\nOverall, the paper presents a clear and well-structured approach to activity recognition in baseball videos, and the results are supported by evidence from the dataset. The paper also provides a good overview of the related work in the field, making it a publishable research paper.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 200, 'prompt_tokens': 771, 'total_tokens': 971, 'completion_time': 0.166666667, 'prompt_time': 0.096472051, 'queue_time': 0.020469948, 'total_time': 0.263138718}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_6a6771ae9c', 'finish_reason': 'stop', 'logprobs': None} id='run-a2cbaab8-41aa-42a6-8ccf-dca2c923f590-0' usage_metadata={'input_tokens': 771, 'output_tokens': 200, 'total_tokens': 971}\n",
            "Response: content='I would classify this research paper as \"Publishable\".\\n\\nHere\\'s a brief justification:\\n\\n* Methodology clarity: The paper provides a clear overview of the existing research in the field of activity recognition, including the comparison of pooling techniques and the use of LSTMs, max-pooling, and 3D CNNs. The paper also introduces the dataset used in the study, which is a significant contribution.\\n* Coherence: The paper follows a logical structure, starting with an overview of the existing research, followed by a description of the dataset, and then discussing the methodology used in the study.\\n* Validity: The paper presents evidence-based results, including the comparison of different pooling techniques and the use of 3D CNNs for activity detection. The dataset used in the study is also well-defined and replicable.\\n\\nOverall, the paper presents a clear and well-structured methodology, provides evidence-based results, and contributes to the field of activity recognition. These characteristics are typical of a publishable research paper.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 204, 'prompt_tokens': 774, 'total_tokens': 978, 'completion_time': 0.17, 'prompt_time': 0.096845187, 'queue_time': 0.020665262000000004, 'total_time': 0.266845187}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_6a6771ae9c', 'finish_reason': 'stop', 'logprobs': None} id='run-cfd469a5-6960-4c60-81de-609a837bed64-0' usage_metadata={'input_tokens': 774, 'output_tokens': 204, 'total_tokens': 978}\n",
            "Response: content='Based on the criteria provided, I classify this research paper as \"Publishable\".\\n\\nHere\\'s a brief justification:\\n\\n* Methodology clarity: The paper clearly describes the dataset and its annotation process, which is a crucial aspect of methodology. The description of the dataset\\'s characteristics, such as the inclusion of multiple baseball actions and the use of a multi-label classification task, is also well-defined.\\n* Coherence: The paper follows a logical structure, starting with an introduction to the dataset and its limitations, followed by a description of the dataset\\'s characteristics, and ending with a summary of the annotated data.\\n* Validity: The paper provides evidence to support its claims, such as the inclusion of a collection of hard negative examples and the description of the dataset\\'s limitations. The use of visual aids like Figures 3 and 4 also helps to illustrate the complexity of the task and the importance of considering multiple factors when differentiating between baseball actions.\\n\\nIn contrast to the \"Not Publishable\" example provided, this paper does not make sweeping claims or vague statements about the implications of its research. Instead, it focuses on providing a detailed description of the dataset and its characteristics, which is a crucial aspect of methodology in computer vision research. Overall, I believe that this paper is well-written, clear, and provides sufficient evidence to support its claims, making it a publishable research paper.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 275, 'prompt_tokens': 798, 'total_tokens': 1073, 'completion_time': 0.229166667, 'prompt_time': 0.096630129, 'queue_time': 0.01877258000000001, 'total_time': 0.325796796}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_a97cfe35ae', 'finish_reason': 'stop', 'logprobs': None} id='run-02e7d4de-920f-4b92-afb0-33ac9f1f82ff-0' usage_metadata={'input_tokens': 798, 'output_tokens': 275, 'total_tokens': 1073}\n",
            "Response: content='I would classify this research paper as \"Publishable\".\\n\\nHere\\'s my justification:\\n\\n* Methodology clarity: The paper clearly describes the methodology used to collect and annotate the dataset, as well as the techniques used for aggregating temporal features in segmented video activity recognition. The approach is well-defined and replicable.\\n* Coherence: The paper follows a logical structure, starting with an introduction to the dataset and its characteristics, followed by a description of the methodology and the results.\\n* Validity: The results are justified with evidence, including the presentation of the dataset, the activity classes, and their instance counts, as well as the description of the techniques used for feature pooling and video clip classification.\\n\\nThe paper provides a clear and concise description of the research, and the methodology is well-defined and replicable. The results are justified with evidence, and the paper follows a logical structure. Overall, the paper meets the criteria for being publishable.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 188, 'prompt_tokens': 846, 'total_tokens': 1034, 'completion_time': 0.156666667, 'prompt_time': 0.168748321, 'queue_time': 0.020093287999999987, 'total_time': 0.325414988}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_179b0f92c9', 'finish_reason': 'stop', 'logprobs': None} id='run-06464d46-3eef-48fa-bc9f-042a0fd5e51e-0' usage_metadata={'input_tokens': 846, 'output_tokens': 188, 'total_tokens': 1034}\n",
            "Response: content='I classify this research paper as \"Publishable\".\\n\\nHere\\'s a brief justification for each of the criteria:\\n\\n* Methodology clarity: The paper clearly describes two alternative approaches to processing video data: temporal pyramid pooling and learning temporal convolution filters. The mathematical formulations are well-defined and easy to follow.\\n* Coherence: The paper follows a logical structure, starting with an introduction to the limitations of the initial approach, followed by a description of the two alternative methods, and concluding with a brief discussion of the benefits of learning the sub-intervals.\\n* Validity: The paper provides sufficient evidence to justify the results, including mathematical formulations and figures illustrating the different approaches.\\n\\nOverall, the paper presents a clear and concise description of two alternative methods for processing video data, with well-defined mathematical formulations and logical structure. The results are justified with evidence, making it a publishable paper.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 174, 'prompt_tokens': 900, 'total_tokens': 1074, 'completion_time': 0.145, 'prompt_time': 0.109239554, 'queue_time': 0.018739075000000008, 'total_time': 0.254239554}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_a97cfe35ae', 'finish_reason': 'stop', 'logprobs': None} id='run-1137bf4e-a3d0-48d5-a496-da274279a800-0' usage_metadata={'input_tokens': 900, 'output_tokens': 174, 'total_tokens': 1074}\n",
            "Response: content='I would classify this research paper as \"Publishable\".\\n\\nHere\\'s a brief justification:\\n\\n* Methodology clarity: The paper clearly describes the methodology used, including the normalization constant, matrix multiplication, and the use of a fully-connected layer and bi-directional LSTM for classification. The mathematical equations are well-structured and easy to follow.\\n* Coherence: The paper follows a logical structure, starting with an introduction to the problem, followed by the methodology, and then the results and discussion.\\n* Validity: The results are justified with evidence, as the authors compare different methods and present a baseline approach to activity detection in continuous videos.\\n\\nThe paper presents a clear and concise description of the methodology and results, making it easy to understand and follow. The mathematical equations are well-structured, and the authors provide a clear explanation of the approach. The paper also presents a baseline approach and compares different methods, demonstrating the validity of the results. Overall, the paper meets the criteria for a publishable research paper.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 201, 'prompt_tokens': 814, 'total_tokens': 1015, 'completion_time': 0.1675, 'prompt_time': 0.101385009, 'queue_time': 0.019122198000000007, 'total_time': 0.268885009}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_6a6771ae9c', 'finish_reason': 'stop', 'logprobs': None} id='run-94e088da-808c-4d04-836f-1af08fce5c56-0' usage_metadata={'input_tokens': 814, 'output_tokens': 201, 'total_tokens': 1015}\n",
            "Response: content='I would classify this research paper as \"Publishable\".\\n\\nHere\\'s a brief justification for my classification:\\n\\n* Methodology clarity: The paper clearly explains the methodology used, including the feature extraction techniques, pooling methods, and classification approaches. The notation and equations are concise and well-defined, making it easy to follow the authors\\' approach.\\n* Coherence: The paper follows a logical structure, starting with the introduction of the problem, followed by the description of the methodology, and ending with the results and conclusions.\\n* Validity: The paper provides evidence to support its claims, including the use of mathematical equations, diagrams (e.g., Fig. 5(a)), and a clear explanation of the experimental setup. The authors also provide a detailed description of the training process and the loss function used.\\n\\nOverall, the paper appears to be well-written, and the authors provide sufficient detail to allow for replication of their results. The methodology is clear, and the paper follows a logical structure. While the paper may not be groundbreaking or have far-reaching implications, it appears to be a solid contribution to the field.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 220, 'prompt_tokens': 848, 'total_tokens': 1068, 'completion_time': 0.183333333, 'prompt_time': 0.109106385, 'queue_time': 0.019044057000000003, 'total_time': 0.292439718}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_a97cfe35ae', 'finish_reason': 'stop', 'logprobs': None} id='run-fb38b94f-25c6-47ff-aeb6-f3949b71d459-0' usage_metadata={'input_tokens': 848, 'output_tokens': 220, 'total_tokens': 1068}\n",
            "Response: content='I classify this research paper as \"Publishable\".\\n\\nHere\\'s a brief justification for my classification:\\n\\n* Methodology clarity: The paper provides a clear and well-defined methodology for learning \"super-events\" for activity detection in continuous videos. The equations and formulas are presented in a concise and readable manner, making it easy to understand the approach.\\n* Coherence: The paper follows a logical structure, starting with an introduction to the concept of super-events, followed by the methodology, experiments, and results.\\n* Validity: The paper presents a clear justification for the results, providing evidence from experiments and comparisons with other approaches. The use of pre-trained CNNs and state-of-the-art performance on segmented video tasks adds credibility to the results.\\n\\nIn general, the paper provides a clear and well-structured presentation of the research, making it suitable for publication in a reputable journal or conference. The methodology is well-defined, the paper is coherent, and the results are justified with evidence, which are all important criteria for a publishable paper.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 206, 'prompt_tokens': 881, 'total_tokens': 1087, 'completion_time': 0.171666667, 'prompt_time': 0.165729013, 'queue_time': 0.019359027, 'total_time': 0.33739568}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_6a6771ae9c', 'finish_reason': 'stop', 'logprobs': None} id='run-2188c448-dc8f-498a-b6ce-a5850eaf500b-0' usage_metadata={'input_tokens': 881, 'output_tokens': 206, 'total_tokens': 1087}\n",
            "Response: content='I classify this research paper as \"Publishable\".\\n\\nHere\\'s a brief justification for my classification:\\n\\n* Methodology clarity: The paper provides a clear description of the methodology used, including the extraction of frames, computation of optical flow, and implementation of the models in PyTorch. The details of the training process, such as the optimizer, learning rate, and number of epochs, are also provided. This level of clarity is suitable for a research paper.\\n* Coherence: The paper follows a logical structure, starting with an introduction to the problem, followed by a description of the methodology, and then presenting the results. The results are presented in a clear and concise manner, with tables and figures used to illustrate the performance of different models.\\n* Validity: The results are justified with evidence, as the paper presents tables and figures to demonstrate the performance of different models and feature aggregation methods. The paper also discusses the importance of preserving temporal structure for activity recognition, which is a valid contribution to the field.\\n\\nOverall, the paper provides a clear and concise description of the methodology and results, and presents a valid contribution to the field of activity recognition.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 230, 'prompt_tokens': 869, 'total_tokens': 1099, 'completion_time': 0.191666667, 'prompt_time': 0.173005775, 'queue_time': 0.020821511999999986, 'total_time': 0.364672442}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_179b0f92c9', 'finish_reason': 'stop', 'logprobs': None} id='run-daf9e706-2635-4938-8899-15700bc141f1-0' usage_metadata={'input_tokens': 869, 'output_tokens': 230, 'total_tokens': 1099}\n",
            "Response: content='I would classify this research paper as \"Publishable\".\\n\\nHere\\'s a brief justification:\\n\\n* Methodology clarity: The paper clearly explains the different models and their parameters, making it easy to replicate the experiments. The tables (e.g., Table 3, Table 4, and Table 5) provide a concise and organized summary of the results.\\n* Coherence: The paper follows a logical structure, starting with an introduction, followed by a description of the methodology, and then presenting the results. The results are then discussed and interpreted in the conclusion.\\n* Validity: The paper provides evidence to support its claims, such as the results presented in the tables. The conclusions drawn from the results are reasonable and well-supported.\\n\\nOverall, the paper presents a clear and concise description of a research study, with well-organized tables and figures that support the results. The methodology is well-defined, and the conclusions are justified by the evidence presented. This meets the criteria for a publishable paper.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 199, 'prompt_tokens': 1005, 'total_tokens': 1204, 'completion_time': 0.165833333, 'prompt_time': 0.124810369, 'queue_time': 0.019962639000000004, 'total_time': 0.290643702}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_6a6771ae9c', 'finish_reason': 'stop', 'logprobs': None} id='run-5d3c5b6a-839a-4193-a127-9af9f1d83cd8-0' usage_metadata={'input_tokens': 1005, 'output_tokens': 199, 'total_tokens': 1204}\n",
            "Response: content='I classify this research paper as \"Publishable\".\\n\\nHere\\'s a brief justification based on the given criteria:\\n\\n1. Methodology clarity: The paper provides a clear description of the methodology used, including the types of features extracted (frame-based and segment-based), the architectures used (InceptionV3 and I3D), and the evaluation metrics (per-class average precision). The paper also explains the concept of sub-event learning and its advantages in detecting specific baseball events.\\n2. Coherence: The paper follows a logical structure, starting with an introduction to the problem, followed by a description of the methodology, and then presenting the results. The paper also provides relevant figures and tables to support the claims made.\\n3. Validity: The results presented in the paper are justified with evidence from the experiments. The tables and figures provide quantitative and qualitative insights into the performance of the proposed methods, and the paper discusses the implications of the results.\\n\\nOverall, the paper presents a clear and well-structured description of the methodology and results, making it a publishable paper.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 213, 'prompt_tokens': 962, 'total_tokens': 1175, 'completion_time': 0.1775, 'prompt_time': 0.383901549, 'queue_time': 0.02000405799999999, 'total_time': 0.561401549}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_179b0f92c9', 'finish_reason': 'stop', 'logprobs': None} id='run-25471ca8-22ca-4c7f-86a8-9fc3eefd7c98-0' usage_metadata={'input_tokens': 962, 'output_tokens': 213, 'total_tokens': 1175}\n",
            "Response: content='I classify this research paper as \"Publishable\".\\n\\nHere\\'s a brief justification for my classification:\\n\\n* Methodology clarity: The paper provides a clear description of the methodology used to calculate optical flow, extract RGB frames, and train the models for pitch speed prediction and pitch type classification. The use of tables and figures to present the results also helps to clarify the methodology.\\n* Coherence: The paper follows a logical structure, starting with the introduction and background, followed by the methodology, results, and discussion. The authors present their findings in a clear and organized manner.\\n* Validity: The paper provides evidence to support its claims, including tables and figures that present the results of the experiments. The comparison of different models and the presentation of the results for each model (Table 6) demonstrate the validity of the approach.\\n\\nOverall, the paper presents a clear and well-structured methodology, provides evidence to support its claims, and addresses a specific research question. These factors contribute to a high level of publishability.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 203, 'prompt_tokens': 843, 'total_tokens': 1046, 'completion_time': 0.169166667, 'prompt_time': 0.102805343, 'queue_time': 0.01972889600000001, 'total_time': 0.27197201}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_a97cfe35ae', 'finish_reason': 'stop', 'logprobs': None} id='run-aab98cbe-06ab-4493-8e87-5a81523fac39-0' usage_metadata={'input_tokens': 843, 'output_tokens': 203, 'total_tokens': 1046}\n",
            "Response: content='I classify this research paper as \"Publishable\".\\n\\nHere\\'s a brief justification:\\n\\n* Methodology clarity: The paper clearly describes the methodology used to evaluate the models for pitch type classification and continuous video activity detection. The tables and figures provide a clear representation of the results, making it easy to understand and replicate the experiments.\\n* Coherence: The paper follows a logical structure, starting with an introduction to the problem, followed by the methodology, results, and discussion of the findings. The sections are well-organized and easy to follow.\\n* Validity: The results are justified with evidence from the tables and figures, and the paper provides a clear explanation of the implications of the findings. The use of multiple models and evaluation metrics adds to the validity of the results.\\n\\nThe paper presents a clear and well-structured evaluation of different models for pitch type classification and continuous video activity detection, providing a solid contribution to the field. The methodology is well-defined, and the results are presented in a clear and concise manner, making it easy to understand and replicate the experiments.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 213, 'prompt_tokens': 953, 'total_tokens': 1166, 'completion_time': 0.1775, 'prompt_time': 0.20098769, 'queue_time': 0.11208243699999998, 'total_time': 0.37848769}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_179b0f92c9', 'finish_reason': 'stop', 'logprobs': None} id='run-d85aa15c-9667-42ed-99f2-80d1565edc25-0' usage_metadata={'input_tokens': 953, 'output_tokens': 213, 'total_tokens': 1166}\n",
            "Response: content='I would classify this research paper as \"Publishable\".\\n\\nHere\\'s my justification based on the criteria:\\n\\n* Methodology clarity: The paper clearly describes the dataset (MLB-YouTube) and the various recognition techniques used, including the models employed (InceptionV3 + various pooling methods) and the comparison of their performance.\\n* Coherence: The paper follows a logical structure, starting with an introduction to the dataset and problem, followed by a description of the methods used, and concluding with the results and findings.\\n* Validity: The results are justified with evidence, as the paper presents tables and comparisons of the performance of different models, providing a clear evaluation of their effectiveness.\\n\\nOverall, the paper presents a clear and focused research question, uses appropriate methodologies, and provides evidence-based results. The writing is concise and to the point, making it easy to follow and understand the research.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 178, 'prompt_tokens': 752, 'total_tokens': 930, 'completion_time': 0.148333333, 'prompt_time': 0.094108257, 'queue_time': 0.019761850999999997, 'total_time': 0.24244159}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_6a6771ae9c', 'finish_reason': 'stop', 'logprobs': None} id='run-64125e77-e4e7-4da0-93b4-d5d45f56b7c4-0' usage_metadata={'input_tokens': 752, 'output_tokens': 178, 'total_tokens': 930}\n",
            "content='Final Summary:\\n\\nThe research paper evaluations in this batch of summaries consistently highlight the importance of clear methodology, coherence, and validity in research papers. The evaluators praised the papers for providing concise and organized descriptions of the methodology, using logical structures, and presenting evidence-based results. The papers were also commended for their clear explanations of the implications of the findings and their contributions to the field.\\n\\nThe evaluators found that most of the papers in this batch presented clear and well-structured methodology, coherence, and validity, leading to positive justifications for publication. The authors\\' descriptions of their datasets, methods, and results were well-defined and replicable, and they provided evidence to support their claims. The papers presented valid contributions to their respective fields, and the results were justified with evidence.\\n\\nHowever, it is not all positive, as one paper in each of the batches was classified as \"Not Publishable\" due to the lack of clarity in its methodology and results. This highlights the importance of rigorous evaluation and attention to detail in research papers.\\n\\nTotal Publishable Count: 12\\n\\nTotal Not Publishable Count: 3\\n\\nFinal Classification: Publishable\\n\\nThe results indicate that the majority of the research papers in this batch are Publishable, with 12 papers receiving positive evaluations and only 3 classified as Not Publishable. This suggests that the papers in this batch are of high quality and have the potential to make a significant contribution to their respective fields.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 291, 'prompt_tokens': 582, 'total_tokens': 873, 'completion_time': 0.2425, 'prompt_time': 0.114753732, 'queue_time': 0.018818596999999992, 'total_time': 0.357253732}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_179b0f92c9', 'finish_reason': 'stop', 'logprobs': None} id='run-7cff3353-a1bb-40d9-98a7-f1e41ea92a9d-0' usage_metadata={'input_tokens': 582, 'output_tokens': 291, 'total_tokens': 873}\n",
            "The paper is not deemed publishable.\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"stormintegration.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/github/Harshal292004/KGPDSH/blob/master/stormintegration.ipynb\n",
        "\"\"\"\n",
        "\n",
        "from langchain.prompts.chat import ChatPromptTemplate\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from pydantic import BaseModel, Field, validator, PrivateAttr\n",
        "from typing import List, Dict\n",
        "from google.colab import userdata\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "import re, json, os\n",
        "import uuid\n",
        "\n",
        "os.environ['HF_TOKEN'] = userdata.get('HF_TOKEN')\n",
        "class ScoreDetails(BaseModel):\n",
        "    score: float = Field(description=\"Score of the aspect (0-10)\")\n",
        "    justification: str = Field(description=\"Explanation for the score\")\n",
        "\n",
        "    @validator('score')\n",
        "    def validate_score(cls, v: float) -> float:\n",
        "        if v < 0 or v > 10:\n",
        "            raise ValueError('Score must be between 0 and 10')\n",
        "        return round(v, 1)\n",
        "\n",
        "# Evaluation Categories for Publishability Assessment\n",
        "class MethodologyEvaluation(BaseModel):\n",
        "    research_design: ScoreDetails = Field(description=\"Appropriateness and quality of research design\")\n",
        "    reproducibility: ScoreDetails = Field(description=\"Clarity and completeness of methods for reproduction\")\n",
        "\n",
        "class CoherenceEvaluation(BaseModel):\n",
        "    logical_flow: ScoreDetails = Field(description=\"Logical flow and structure of the paper\")\n",
        "    clarity: ScoreDetails = Field(description=\"Clarity and effectiveness of writing\")\n",
        "\n",
        "class ValidityEvaluation(BaseModel):\n",
        "    evidence_strength: ScoreDetails = Field(description=\"Strength and relevance of evidence provided\")\n",
        "    validation: ScoreDetails = Field(description=\"Validation of claims and findings\")\n",
        "\n",
        "class PublishabilityEvaluation(BaseModel):\n",
        "    methodology: MethodologyEvaluation = Field(description=\"Detailed methodology assessment\")\n",
        "    coherence: CoherenceEvaluation = Field(description=\"Coherence and clarity assessment\")\n",
        "    validity: ValidityEvaluation = Field(description=\"Validity of claims and evidence\")\n",
        "\n",
        "class PaperEvaluation(BaseModel):\n",
        "    paper_id: str = Field(description=\"Unique identifier for the paper\")\n",
        "    publishable: bool = Field(description=\"Whether the paper is deemed publishable\")\n",
        "    scores: PublishabilityEvaluation = Field(description=\"Scores for publishability evaluation\")\n",
        "    justification: str = Field(description=\"Overall justification for publishability decision\")\n",
        "    summary_of_paper: str = Field(description=\"Summary of the paper for retrieval and further analysis\")\n",
        "\n",
        "# Implementing STORM Architecture for Conference Selection\n",
        "class ConferenceAgent:\n",
        "    def __init__(self, name: str, chat_model: ChatGroq, target_conference: str , conference_themes: str, conference_context:str):\n",
        "        self.name = name\n",
        "        self.chat_model = chat_model\n",
        "        self.target_conference = target_conference\n",
        "        self.conference_themes = conference_themes\n",
        "        self.conference_context = conference_context\n",
        "\n",
        "    def evaluate_paper(self, paper_summary: str ) -> Dict:\n",
        "        prompt = ChatPromptTemplate.from_messages([\n",
        "            ('system',  f\"\"\"\n",
        "            You are a representative for the conference {self.target_conference}. Strictly Focus Specially on the conference themes: {self.conference_themes}\n",
        "            Use the following additional context to guide your evaluation:\n",
        "            {self.conference_context}\n",
        "\n",
        "            Evaluate the research paper based on:\n",
        "            - Relevance to conference themes\n",
        "            - Quality of methodology\n",
        "            - Novelty of contribution\n",
        "            Provide a score (0-10) and a justification for why the paper fits this conference.\n",
        "            Respond is json format with the following keys\n",
        "            - score: float\n",
        "            - justification: str\n",
        "            \"\"\"),\n",
        "            ('user', \"Paper summary: {paper_summary}\")\n",
        "        ])\n",
        "        chain = LLMChain(llm = self.chat_model, prompt=prompt)\n",
        "        response = chain.run({\"paper_summary\": paper_summary})\n",
        "        try:\n",
        "            # Preprocess the response to clean up invalid characters\n",
        "            cleaned_response = re.sub(r'[\\x00-\\x1F\\x7F]', '', response)  # Remove control characters\n",
        "            json_match = re.search(r'\\{.*\\}', cleaned_response, re.DOTALL)\n",
        "            if json_match:\n",
        "                json_response = json_match.group(0)\n",
        "                response_dict = json.loads(json_response)\n",
        "                return {\n",
        "                    \"score\": float(response_dict[\"score\"]),\n",
        "                    \"justification\": response_dict[\"justification\"],\n",
        "                }\n",
        "            else:\n",
        "                raise ValueError(f\"No JSON object found in the response: {response}\")\n",
        "        except json.JSONDecodeError as e:\n",
        "            raise ValueError(f\"Failed to parse response as JSON: {response}\") from e\n",
        "\n",
        "class STORMSystem:\n",
        "    def __init__(self, agents: List[ConferenceAgent]):\n",
        "        self.agents = agents\n",
        "\n",
        "    def discuss_and_decide(self, paper_summary: str) -> Dict:\n",
        "        evaluations = []\n",
        "        for agent in self.agents:\n",
        "            evaluation = agent.evaluate_paper(paper_summary)\n",
        "            evaluations.append({\n",
        "                \"conference\": agent.target_conference,\n",
        "                \"score\": evaluation[\"score\"],\n",
        "                \"justification\": evaluation[\"justification\"],\n",
        "            })\n",
        "\n",
        "        # Determine the best conference based on scores\n",
        "        best_conference = max(evaluations, key=lambda x: x[\"score\"])\n",
        "        return {\n",
        "            \"best_conference\": best_conference[\"conference\"],\n",
        "            \"justification\": best_conference[\"justification\"],\n",
        "        }\n",
        "\n",
        "# Integrating Publishability Assessment\n",
        "import re\n",
        "import uuid\n",
        "import json\n",
        "\n",
        "class PublishabilityEvaluator:\n",
        "    def __init__(self, chat_model: ChatGroq, publishable_retriever, not_publishable_retriever, example_publishable, example_not_publishable):\n",
        "        \"\"\"\n",
        "        Initialize the evaluator with LLM and retrievers for publishable and not-publishable examples.\n",
        "        \"\"\"\n",
        "        self.chat_model = chat_model\n",
        "        self.publishable_retriever = publishable_retriever\n",
        "        self.not_publishable_retriever = not_publishable_retriever\n",
        "        self.example_publishable = example_publishable\n",
        "        self.example_not_publishable = example_not_publishable\n",
        "\n",
        "    def evaluate_publishability(self, paper_text: str) -> dict:\n",
        "        \"\"\"\n",
        "        Evaluate the publishability of a research paper using chunking and example-based classification.\n",
        "        \"\"\"\n",
        "        # Prepare the examples\n",
        "        prompt = f\"\"\"\n",
        "        You will be given a research paper, and your task is to classify it as \"Publishable\" or \"Not Publishable\".\n",
        "        For reference, I have provided two examples:\n",
        "\n",
        "        1. Publishable Paper:\n",
        "        {self.example_publishable}\n",
        "\n",
        "        2. Not Publishable Paper:\n",
        "        {self.example_not_publishable}\n",
        "\n",
        "        Criteria for classification:\n",
        "        - Methodology clarity: Is the methodology well-defined and replicable?\n",
        "        - Coherence: Does the paper follow a logical structure?\n",
        "        - Validity: Are the results justified with evidence?\n",
        "\n",
        "        Now, analyze the following research paper and provide your classification along with a brief justification.\n",
        "        \"\"\"\n",
        "\n",
        "        # Chunk the input paper\n",
        "        chunks = self.chunk_text(paper_text)\n",
        "        chunk_results = []  # To collect classification and justification per chunk\n",
        "\n",
        "        for chunk in chunks:\n",
        "            context = f\"{prompt}\\n\\nResearch Paper:\\n{chunk}\"\n",
        "            try:\n",
        "                response = self.chat_model.invoke(context)\n",
        "                print(\"Response:\", response)\n",
        "\n",
        "                # Extract classification and justification\n",
        "                classification = \"Publishable\" if \"Classification: Publishable\" in response.content else \"Not Publishable\"\n",
        "                justification = response.content  # Assuming full content includes justification\n",
        "\n",
        "                chunk_results.append({\n",
        "                    \"chunk_text\": chunk,\n",
        "                    \"classification\": classification,\n",
        "                    \"justification\": justification,\n",
        "                })\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing chunk: {e}\")\n",
        "\n",
        "        return {\n",
        "            \"chunk_results\": chunk_results,\n",
        "        }\n",
        "\n",
        "    def summarize_in_batches(self, chunk_results: list, batch_size: int = 5) -> dict:\n",
        "        \"\"\"\n",
        "        Summarize chunk results in batches to handle context length limits.\n",
        "        \"\"\"\n",
        "        summaries = []\n",
        "        for i in range(0, len(chunk_results), batch_size):\n",
        "            batch = chunk_results[i:i + batch_size]\n",
        "            batch_prompt = f\"\"\"\n",
        "            You are analyzing a batch of research paper evaluations. Each chunk has been classified as\n",
        "            \"Publishable\" or \"Not Publishable\" with a justification. Summarize the justifications for this batch\n",
        "            and provide a batch-level conclusion.\n",
        "\n",
        "            Batch Evaluations:\n",
        "            {json.dumps(batch, indent=2)}\n",
        "\n",
        "            Respond with:\n",
        "            - Batch Summary: A summary of the justifications for this batch.\n",
        "            - Publishable Count: The number of chunks classified as Publishable in this batch.\n",
        "            - Not Publishable Count: The number of chunks classified as Not Publishable in this batch.\n",
        "            \"\"\"\n",
        "\n",
        "            response = self.chat_model.invoke(batch_prompt)\n",
        "            try:\n",
        "                result = json.loads(response.content)\n",
        "                summaries.append(result)\n",
        "            except json.JSONDecodeError:\n",
        "                summaries.append({\"batch_summary\": response.content, \"publishable_count\": 0, \"not_publishable_count\": 0})\n",
        "\n",
        "        # Combine all summaries into a final prompt\n",
        "        combined_prompt = f\"\"\"\n",
        "        You have received summaries of multiple batches of research paper evaluations. Combine these summaries into\n",
        "        a final 500-word summary. Also calculate the total Publishable and Not Publishable counts across all batches\n",
        "        and determine the final classification.\n",
        "\n",
        "        Batch Summaries:\n",
        "        {json.dumps(summaries, indent=2)}\n",
        "\n",
        "        Respond with:\n",
        "        - Final Summary: A 500-word summary combining all batch summaries.\n",
        "        - Total Publishable Count: The total number of Publishable classifications.\n",
        "        - Total Not Publishable Count: The total number of Not Publishable classifications.\n",
        "        - Final Classification: \"Publishable\" or \"Not Publishable\" based on the higher count.\n",
        "        \"\"\"\n",
        "        response = self.chat_model.invoke(combined_prompt)\n",
        "        print(response)\n",
        "        try:\n",
        "            return json.loads(response.content)\n",
        "        except json.JSONDecodeError:\n",
        "            return {\"final_summary\": response.content, \"final_classification\": \"Error\"}\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def chunk_text(text, max_chunk_size=1500):\n",
        "        \"\"\"\n",
        "        Split text into manageable chunks for processing.\n",
        "        \"\"\"\n",
        "        return [text[i:i + max_chunk_size] for i in range(0, len(text), max_chunk_size)]\n",
        "\n",
        "\n",
        "# Loading and Chunking the Paper\n",
        "    def load_and_chunk_paper(file_path: str, chunk_size: int = 500, overlap: int = 50) -> str:\n",
        "            \"\"\"Load a research paper and split it into manageable chunks.\"\"\"\n",
        "            loader = PyPDFLoader(file_path)\n",
        "            pages = loader.load()\n",
        "            full_text = \" \".join([page.page_content for page in pages])\n",
        "            splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=overlap)\n",
        "            chunks = splitter.split_text(full_text)\n",
        "            return \" \".join(chunks)  # Combine chunks for processing\n",
        "\n",
        "    def recursively_get_pdf_files(directory):\n",
        "        pdf_files = []\n",
        "        try:\n",
        "            if os.path.isfile(directory) and directory.endswith('.pdf'):\n",
        "                pdf_files.append(directory)\n",
        "            elif os.path.isdir(directory):\n",
        "                for file in os.listdir(directory):\n",
        "                    full_path = os.path.join(directory, file)\n",
        "                    pdf_files.extend(PublishabilityEvaluator.recursively_get_pdf_files(full_path))\n",
        "        except Exception as e:\n",
        "            print(f\"Error accessing {directory}: {e}\")\n",
        "        return pdf_files\n",
        "\n",
        "    def load_docs(list_of_pdf_paths):\n",
        "        document_list=[]\n",
        "        for pdf_path in list_of_pdf_paths:\n",
        "          loader = PyPDFLoader(pdf_path)\n",
        "          document_list.append(loader.load())\n",
        "        return document_list\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    chat_model = ChatGroq(groq_api_key=userdata.get(\"GROQ_API_KEY\").strip(), model=\"llama3-8b-8192\")\n",
        "\n",
        "    # Load and chunk the research paper\n",
        "    paper_path = \"/content/drive/MyDrive/KDSH_2025_Dataset/Reference/Publishable/CVPR/R006.pdf\"\n",
        "    paper_text = PublishabilityEvaluator.load_and_chunk_paper(paper_path)\n",
        "\n",
        "    list_of_files1=PublishabilityEvaluator.recursively_get_pdf_files('/content/drive/MyDrive/KDSH_2025_Dataset/Reference/Publishable')\n",
        "    list_of_files2=PublishabilityEvaluator.recursively_get_pdf_files('/content/drive/MyDrive/KDSH_2025_Dataset/Reference/Non-Publishable')\n",
        "\n",
        "    document_list1= PublishabilityEvaluator.load_docs(list_of_files1)\n",
        "    document_list2 = PublishabilityEvaluator.load_docs(list_of_files2)\n",
        "\n",
        "    split_text = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=256)\n",
        "\n",
        "    split_docs1 = split_text.split_documents(document_list1[0])\n",
        "    split_docs2 = split_text.split_documents(document_list2[0])\n",
        "\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "    vectorestore1 = FAISS.from_documents(split_docs1, embeddings)\n",
        "    vectorestore2 = FAISS.from_documents(split_docs2, embeddings)\n",
        "\n",
        "    retreiver1 = vectorestore1.as_retriever()\n",
        "    retreiver2 = vectorestore2.as_retriever()\n",
        "\n",
        "    publishable_context = vectorestore1.similarity_search(\"Methodology, coherence, and validity examples\", k=1)\n",
        "    not_publishable_context = vectorestore2.similarity_search(\"Methodology, coherence, and validity examples\", k=1)\n",
        "\n",
        "    # Fallback if no results\n",
        "    paper1 = publishable_context[0].page_content if publishable_context else \"Default Publishable Example\"\n",
        "    paper2 = not_publishable_context[0].page_content if not_publishable_context else \"Default Not Publishable Example\"\n",
        "\n",
        "    # Publishability Evaluation\n",
        "    publishability_evaluator = PublishabilityEvaluator(chat_model=chat_model,publishable_retriever=retreiver1,not_publishable_retriever=retreiver2, example_publishable=paper1,example_not_publishable=paper2 )\n",
        "    chunk_results = publishability_evaluator.evaluate_publishability(paper_text)[\"chunk_results\"]\n",
        "\n",
        "    final_result = publishability_evaluator.summarize_in_batches(chunk_results)\n",
        "\n",
        "     # Extract final classification and summary\n",
        "    final_classification = final_result.get(\"Final classification\")\n",
        "    final_summary = final_result.get(\"summary\")\n",
        "\n",
        "\n",
        "    if final_classification == \"Publishable\":\n",
        "        # Conference Selection\n",
        "        agents = [\n",
        "            ConferenceAgent(name=\"Agent CVPR\", chat_model=chat_model, target_conference=\"CVPR\", conference_themes = \"\"\"\n",
        "                        CVPR focuses on the field of computer vision, image processing, and pattern recognition. Key themes include:\n",
        "                          Object detection and recognition.\n",
        "                          Image segmentation and scene understanding.\n",
        "                          Visual tracking and motion analysis.\n",
        "                          3D vision, stereo vision, and depth estimation.\n",
        "                          Deep learning for vision tasks (CNNs, Vision Transformers, etc.).\n",
        "                          Applications in medical imaging, autonomous vehicles, and robotics.\n",
        "                          Video processing and understanding.\n",
        "                          Computational photography and imaging.\n",
        "                          Low-level vision (denoising, super-resolution).\n",
        "                          Vision-based augmented reality and virtual reality.\n",
        "                        \"\"\",\n",
        "                        conference_context = \"\"\"\n",
        "                        Examples of accepted papers:\n",
        "                          - YOLO: Real-Time Object Detection\n",
        "                              Summary: Proposes an efficient deep learning model for real-time object detection with state-of-the-art accuracy.\n",
        "                          - SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation\n",
        "                              Summary: Focuses on pixel-wise image segmentation using deep neural networks, with applications in autonomous systems.\n",
        "                          - 3D Object Detection and Localization Using RGB and Depth Data\n",
        "                              Summary: Combines RGB and depth information for accurate 3D object detection in indoor environments.\n",
        "                        Evaluation Criteria:\n",
        "                         - Relevance to core computer vision topics.\n",
        "                         - Advances in methodology or application.\n",
        "                         - Practical implications for industries like healthcare, robotics, and transportation.\n",
        "                        \"\"\"),\n",
        "            ConferenceAgent(name=\"Agent NeurIPS\", chat_model=chat_model, target_conference=\"NeurIPS\"  ,conference_themes =\"\"\"\n",
        "                        NeurIPS emphasizes machine learning, computational neuroscience, and AI-related topics. Key themes include:\n",
        "                            Deep learning (e.g., architectures, generative models, optimization for deep networks, foundation models, LLMs)\n",
        "                            Reinforcement learning and decision-making.\n",
        "                            Probabilistic models and Bayesian learning.\n",
        "                            Optimization techniques for machine learning.\n",
        "                            Representation learning and embeddings.\n",
        "                            AI for healthcare, climate science, and sustainability.\n",
        "                            Neuroscience-inspired algorithms and theories.\n",
        "                            Ethical AI, fairness, and explainability.\n",
        "                        \"\"\",\n",
        "                        conference_context = \"\"\"\n",
        "                        Examples of accepted papers:\n",
        "                          - Attention Is All You Need\n",
        "                             Summary: Introduces the transformer architecture, which revolutionized NLP and other domains by using self-attention mechanisms.\n",
        "                          - Generative Adversarial Networks (GANs)\n",
        "                             Summary: Proposes a novel framework for training generative models using adversarial networks.\n",
        "                          - Adam: A Method for Stochastic Optimization\n",
        "                             Summary: Proposes a new optimization algorithm that balances convergence speed and stability in deep learning.\n",
        "                        Evaluation Criteria:\n",
        "                          - Novelty and theoretical contributions.\n",
        "                          - Experimental rigor and reproducibility.\n",
        "                          - Broader implications for machine learning and interdisciplinary applications.\n",
        "                        \"\"\"),\n",
        "            ConferenceAgent(name=\"Agent EMNLP\", chat_model=chat_model, target_conference=\"EMNLP\" ,conference_themes = \"\"\"\n",
        "                        EMNLP specializes in NLP and computational linguistics. Key themes include:\n",
        "                          Machine translation and cross-lingual NLP.\n",
        "                          Large language models and foundational models.\n",
        "                          Sentiment analysis and opinion mining.\n",
        "                          Dialogue systems and conversational AI.\n",
        "                          Question answering and information retrieval.\n",
        "                          Text summarization and abstraction.\n",
        "                          Morphology, syntax, and semantics.\n",
        "                          Multimodal NLP (text + image/audio fusion).\n",
        "                          Ethical concerns in NLP (bias, toxicity detection).\n",
        "                          Low-resource and multilingual NLP.\n",
        "                        \"\"\",\n",
        "                        conference_context = \"\"\"\n",
        "                        Examples of accepted papers:\n",
        "\n",
        "Paper Title: Pre-trained Language Models for Text-to-Text Generation\n",
        "Summary: This paper explores pre-trained models (e.g., T5) for a variety of text-to-text NLP tasks, showcasing improvements across summarization, question answering, and translation.\n",
        "\n",
        "Paper Title: Adversarial Training for Robust Text Classification\n",
        "Summary: Proposes an adversarial training framework that enhances the robustness of text classification models against noisy and adversarial inputs.\n",
        "\n",
        "Paper Title: Knowledge-Enhanced Contextual Representations for Entity Linking\n",
        "Summary: Combines external knowledge sources with contextual embeddings to improve entity linking in complex domains.\n",
        "\n",
        "Paper Title: Multimodal Sentiment Analysis with Attention Mechanisms\n",
        "Summary: Introduces a framework for combining visual and textual inputs to improve sentiment detection in videos.\n",
        "\n",
        "Evaluation Criteria:\n",
        "Relevance to NLP:\n",
        "\n",
        "Papers should directly address core NLP tasks, methodologies, or applications.\n",
        "Emphasis on empirical evaluation and innovation in language processing methods.\n",
        "Quality of Methodology:\n",
        "\n",
        "Rigorous experiments, proper baselines, and thorough ablation studies.\n",
        "Use of diverse and large-scale datasets to validate results.\n",
        "Novelty of Contribution:\n",
        "\n",
        "New architectures, algorithms, or findings that advance the field.\n",
        "Extensions of existing methods to novel tasks or domains.\n",
        "Broader Impacts:\n",
        "\n",
        "Ethical implications of the research (e.g., bias in models, data privacy).\n",
        "Potential for cross-disciplinary applications (e.g., in healthcare, education, or social media).\n",
        "Themes Breakdown with Examples:\n",
        "Natural Language Understanding:\n",
        "\n",
        "Semantic role labeling, coreference resolution, and discourse parsing.\n",
        "Example: A New Framework for Semantic Parsing Using Pre-Trained Transformers.\n",
        "Language Generation:\n",
        "\n",
        "Dialogue systems, machine translation, and creative text generation.\n",
        "Example: Controlled Text Generation with Discrete and Continuous Latent Variables.\n",
        "Information Extraction:\n",
        "\n",
        "Named entity recognition, relation extraction, and knowledge graph construction.\n",
        "Example: Joint Entity and Relation Extraction with Transformer-Based Models.\n",
        "Multimodal NLP:\n",
        "\n",
        "Integrating vision, audio, and textual modalities.\n",
        "Example: Aligning Text and Vision for Multimodal Machine Translation.\n",
        "Social and Ethical Considerations:\n",
        "\n",
        "Bias, fairness, interpretability, and environmental impacts of NLP models.\n",
        "Example: Bias Mitigation in Pre-trained Models: A Data Augmentation Approach.\n",
        "\n",
        "                        \"\"\"),\n",
        "            ConferenceAgent(name=\"Agent KDD\", chat_model=chat_model, target_conference=\"KDD\"  ,conference_themes = \"\"\"\n",
        "                        KDD centers on data mining, big data, and applied AI. Key themes include:\n",
        "                            Scalable data mining algorithms.\n",
        "                            Graph data and network analysis.\n",
        "                            Temporal and sequential data mining.\n",
        "                            Anomaly detection and predictive modeling.\n",
        "                            Recommender systems and personalization.\n",
        "                            Causal inference and counterfactual reasoning.\n",
        "                            Applications in finance, e-commerce, and marketing.\n",
        "                            Data visualization and interpretability.\n",
        "                            Data ethics and privacy-preserving techniques.\n",
        "                            AI and data-driven solutions for social good.\n",
        "                        \"\"\",\n",
        "\n",
        "                        conference_context=\"\"\"\n",
        "                        Examples of accepted papers:\n",
        "\n",
        "Paper Title: Scalable Graph Neural Networks for Large-Scale Social Network Analysis\n",
        "Summary: Introduces a scalable GNN framework that handles billion-scale graphs with high efficiency, showcasing applications in social network analysis.\n",
        "\n",
        "Paper Title: Causal Discovery in High-Dimensional Data Using Deep Learning\n",
        "Summary: Proposes a deep learning-based approach for identifying causal relationships in high-dimensional data.\n",
        "\n",
        "Paper Title: Fair Representation Learning with Adversarial Networks\n",
        "Summary: Develops a framework for learning fair data representations while minimizing demographic bias in downstream tasks.\n",
        "\n",
        "Paper Title: Adaptive Online Learning for Real-Time Recommender Systems\n",
        "Summary: Presents an adaptive online learning algorithm that updates recommender system models in real time based on user interactions.\n",
        "\n",
        "Evaluation Criteria:\n",
        "Relevance to Knowledge Discovery and Data Mining:\n",
        "\n",
        "Papers must address core challenges in data mining, machine learning, or related applications.\n",
        "Emphasis on practical applications and scalability to real-world data.\n",
        "Methodological Rigor:\n",
        "\n",
        "Strong theoretical foundations or innovative empirical methodologies.\n",
        "Comprehensive experiments with real-world datasets and benchmarks.\n",
        "Scalability and Efficiency:\n",
        "\n",
        "Solutions must handle large-scale data effectively, both in computation and memory.\n",
        "Novelty and Impact:\n",
        "\n",
        "New techniques, algorithms, or applications that significantly advance the state-of-the-art.\n",
        "Real-world relevance and potential societal or economic impact.\n",
        "Broader Implications:\n",
        "\n",
        "Ethical considerations, such as fairness, transparency, and responsible use of data.\n",
        "Long-term applicability across industries and domains.\n",
        "                        \"\"\"),\n",
        "        ]\n",
        "\n",
        "        storm_system = STORMSystem(agents=agents)\n",
        "        decision = storm_system.discuss_and_decide(paper_text)\n",
        "\n",
        "\n",
        "        print(f\"Paper ID: {final_result.paper_id}\")\n",
        "        print(f\"Overall Publishability: {final_result.publishable}\")\n",
        "        print(f\"Best Conference: {decision['best_conference']}\")\n",
        "        print(f\"Conference Justification: {decision['justification']}\")\n",
        "    else:\n",
        "\n",
        "        print(\"The paper is not deemed publishable.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain_groq langgraph langchain_community pypdf langchain_huggingface faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbQSqpJxcvq5",
        "outputId": "d4832e62-35a4-4a03-cdbc-fc36d358887d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_groq in /usr/local/lib/python3.10/dist-packages (0.2.3)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.10/dist-packages (0.2.61)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.3.14)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
            "Requirement already satisfied: langchain_huggingface in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: groq<1,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain_groq) (0.13.1)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.10/dist-packages (from langchain_groq) (0.3.29)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from langgraph) (2.0.9)\n",
            "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /usr/local/lib/python3.10/dist-packages (from langgraph) (0.1.48)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.11.10)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.14 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.3.14)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.3)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (9.0.0)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (0.27.0)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (3.3.1)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (0.21.0)\n",
            "Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (4.47.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.24.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2024.10.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.67.1)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.14->langchain_community) (0.3.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain_groq) (1.33)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.4->langgraph) (1.1.0)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.12.14)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (11.0.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain_huggingface) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain_huggingface) (0.4.5)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain_groq) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (2.27.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.3.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.0.2)\n",
            "Downloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.9.0.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uxo43JLRc30g",
        "outputId": "4f2ec43b-411c-49f3-c70e-f69ceb6d184e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TijIGk4-df6X",
        "outputId": "3b22110b-17ef-400c-b55d-4dab08b86b13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement python==3.12 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for python==3.12\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "myWyQedCeGhk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}