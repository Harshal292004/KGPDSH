{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPzLyZJX1tt8E4LlfQzf2E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harshal292004/KGPDSH/blob/master/Copy_of_StormArchitecture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6dFPfVFZwx5",
        "outputId": "1f75c50c-36a6-4684-8998-241b7000b832"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-da90471dcdba>:26: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.9/migration/\n",
            "  @validator('score')\n",
            "<ipython-input-7-da90471dcdba>:87: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.9/migration/\n",
            "  @validator('confidence_level')\n",
            "WARNING:root:Unknown kwargs passed to PathwayVectorClient.similarity_search: {'top_k': 3}\n",
            "WARNING:root:Unknown kwargs passed to PathwayVectorClient.similarity_search: {'top_k': 3}\n",
            "WARNING:root:Unknown kwargs passed to PathwayVectorClient.similarity_search: {'top_k': 3}\n",
            "WARNING:root:Unknown kwargs passed to PathwayVectorClient.similarity_search: {'top_k': 3}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation stored locally.\n",
            "Evaluation stored locally.\n",
            "Evaluation stored locally.\n",
            "Evaluation stored locally.\n",
            "Best Conference: NeurIPS\n",
            "Justification: The research has the potential to make a significant contribution to the field of Reinforcement Learning (RL) by addressing the critical issue of plasticity loss, which results in a decline in an agent's performance over time. The proposed approach, plasticity injection, is novel and effective, and the framework's modularity, computational efficiency, and adaptability make it a valuable tool for enhancing the robustness and longevity of RL agents. However, the paper could benefit from more detailed explanations, empirical evaluations, and a more comprehensive evaluation of its generalizability, novelty, and practical implications.\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts.chat import ChatPromptTemplate\n",
        "from pydantic import BaseModel, Field, validator, PrivateAttr\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from google.colab import userdata\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import PathwayVectorClient\n",
        "import os\n",
        "from google.colab import userdata\n",
        "import uuid  # To generate unique IDs\n",
        "import json\n",
        "\n",
        "client = PathwayVectorClient(url=\"https://demo-document-indexing.pathway.stream\")\n",
        "\n",
        "import json\n",
        "import re\n",
        "from typing import List, Dict\n",
        "os.environ[\"HF_TOKEN\"] = userdata.get(\"HF_TOKEN\")\n",
        "\n",
        "class ScoreDetails(BaseModel):\n",
        "    score: float = Field(description=\"Score of the aspect (0-10)\")\n",
        "    justification: str = Field(description=\"Explanation for the score\")\n",
        "\n",
        "    @validator('score')\n",
        "    def validate_score(cls, v: float) -> float:\n",
        "        if v < 0 or v > 10:\n",
        "            raise ValueError('Score must be between 0 and 10')\n",
        "        return round(v, 1)\n",
        "\n",
        "# Evaluation Categories\n",
        "class Significance(BaseModel):\n",
        "    theoretical_contribution: ScoreDetails = Field(description=\"Assessment of theoretical contribution to the field\")\n",
        "    practical_impact: ScoreDetails = Field(description=\"Evaluation of practical applications and real-world impact\")\n",
        "    novelty: ScoreDetails = Field(description=\"Originality of the research and its contribution\")\n",
        "\n",
        "class MethodologyEvaluation(BaseModel):\n",
        "    research_design: ScoreDetails = Field(description=\"Appropriateness and quality of research design\")\n",
        "    reproducibility: ScoreDetails = Field(description=\"Clarity and completeness of methods for reproduction\")\n",
        "\n",
        "class PresentationQuality(BaseModel):\n",
        "    writing_clarity: ScoreDetails = Field(description=\"Clarity and effectiveness of writing\")\n",
        "    organization: ScoreDetails = Field(description=\"Logical flow and structure of the paper\")\n",
        "    literature_review: ScoreDetails = Field(description=\"Comprehensiveness of literature review\")\n",
        "\n",
        "class PaperEvaluation(BaseModel):\n",
        "    paper_id: str = Field(description=\"Unique identifier for the paper\")\n",
        "    significance: Significance = Field(description=\"Evaluation of research significance\")\n",
        "    methodology: MethodologyEvaluation = Field(description=\"Detailed methodology assessment\")\n",
        "    presentation: PresentationQuality = Field(description=\"Quality of presentation\")\n",
        "    confidence_level: float = Field(description=\"Overall confidence in this review (0-10)\")\n",
        "    _overall_score: float = PrivateAttr(default=0.0)\n",
        "    major_strengths: List[str] = Field(description=\"Major strengths of the paper\")\n",
        "    major_weaknesses: List[str] = Field(description=\"Major weaknesses of the paper\")\n",
        "    detailed_feedback: str = Field(description=\"Comprehensive feedback and suggestions\")\n",
        "    summary_of_paper: str = Field(description=\"Relevant summary for retrieval tasks\")\n",
        "\n",
        "    @property\n",
        "    def overall_score(self) -> float:\n",
        "        if self._overall_score == 0.0:\n",
        "            weights = {\n",
        "                'significance': 0.3,\n",
        "                'methodology': 0.5,\n",
        "                'presentation': 0.2,\n",
        "            }\n",
        "\n",
        "            sig_score = (self.significance.theoretical_contribution.score +\n",
        "                         self.significance.practical_impact.score +\n",
        "                         self.significance.novelty.score) / 3\n",
        "\n",
        "            meth_score = (self.methodology.research_design.score +\n",
        "                          self.methodology.reproducibility.score) / 2\n",
        "\n",
        "            pres_score = (self.presentation.writing_clarity.score +\n",
        "                          self.presentation.organization.score +\n",
        "                          self.presentation.literature_review.score) / 3\n",
        "\n",
        "            self._overall_score = round(\n",
        "                weights['significance'] * sig_score +\n",
        "                weights['methodology'] * meth_score +\n",
        "                weights['presentation'] * pres_score ,\n",
        "                3\n",
        "            )\n",
        "        return self._overall_score\n",
        "\n",
        "    @validator('confidence_level')\n",
        "    def validate_confidence(cls, v: float) -> float:\n",
        "        if v < 0 or v > 10:\n",
        "            raise ValueError('Confidence level must be between 0 and 10')\n",
        "        return round(v, 1)\n",
        "\n",
        "    def generate_summary_report(self) -> str:\n",
        "        string = f\"\"\"\n",
        "        Paper Review Summary (ID: {self.paper_id})\n",
        "        ==========================================\n",
        "        Review Confidence: {self.confidence_level}/10\n",
        "        Overall Score: {self.overall_score}/10\n",
        "        Key Strengths:\n",
        "        {chr(10).join(f\"- {strength}\" for strength in self.major_strengths)}\n",
        "\n",
        "        Areas for Improvement:\n",
        "        {chr(10).join(f\"- {weakness}\" for weakness in self.major_weaknesses)}\n",
        "\n",
        "        Detailed Feedback:\n",
        "        {self.detailed_feedback}\n",
        "\n",
        "        Summary of the Paper:\n",
        "        {self.summary_of_paper}\n",
        "        \"\"\"\n",
        "        return string\n",
        "\n",
        "# Implementing STORM Architecture with LangGraph\n",
        "class ConferenceAgent:\n",
        "    def __init__(self, name: str, chat_model: ChatGroq, target_conference: str, conference_themes: str, conference_context: str, vectorstore:PathwayVectorClient):\n",
        "        self.name = name\n",
        "        self.chat_model = chat_model\n",
        "        self.target_conference = target_conference\n",
        "        self.conference_themes = conference_themes\n",
        "        self.conference_context = conference_context\n",
        "        self.vector_store = vectorstore\n",
        "\n",
        "    def retrieve_conference_context(self, paper_summary: str) -> str:\n",
        "        results = self.vector_store.similarity_search(query=paper_summary, top_k=3)\n",
        "        # Filter results for relevance to the conference\n",
        "        return \"\\n\".join([result.page_content for result in results if self.target_conference in result.page_content])\n",
        "\n",
        "    def evaluate_paper(self, paper_summary: str) -> Dict:\n",
        "        prompt = ChatPromptTemplate.from_messages([\n",
        "            ('system',  f\"\"\"\n",
        "                You are the representative for the conference {self.target_conference}.\n",
        "                Theme: {self.conference_themes}\n",
        "                Context: {self.conference_context}\n",
        "\n",
        "                Evaluate the research significance and strengths.\n",
        "                Score it (0-10) and justify why it fits or doesn't for the conference .\n",
        "                Output must follow this JSON schema:\n",
        "                - score: float\n",
        "                - justification: str\n",
        "            \"\"\"),\n",
        "            ('user', \"Paper summary: {paper_summary}\")\n",
        "        ])\n",
        "        chain = LLMChain(llm = self.chat_model, prompt=prompt)\n",
        "        response = chain.run({\"paper_summary\": paper_summary})\n",
        "        try:\n",
        "              cleaned_response = re.sub(r'[\\x00-\\x1F\\x7F]', '', response)\n",
        "              json_match = re.search(r'\\{.*\\}', cleaned_response, re.DOTALL)\n",
        "              if json_match:\n",
        "                  json_response = json_match.group(0)\n",
        "                  response_dict = json.loads(json_response)\n",
        "                  return {\n",
        "                      \"score\": float(response_dict[\"score\"]),\n",
        "                      \"justification\": response_dict[\"justification\"],\n",
        "                  }\n",
        "              else:\n",
        "                  # Fallback for non-JSON responses\n",
        "                  return {\"score\": None, \"justification\": cleaned_response.strip()}\n",
        "        except json.JSONDecodeError as e:\n",
        "              raise ValueError(f\"Failed to parse response as JSON: {response}\") from e\n",
        "\n",
        "\n",
        "\n",
        "class STORMSystem:\n",
        "    def __init__(self, agents: List[ConferenceAgent], vectorstore: PathwayVectorClient):\n",
        "        self.agents = agents\n",
        "        self.vector_store = vectorstore\n",
        "\n",
        "    def retrieve_context(self, paper_summary: str, target_conference: str) -> List[Dict]:\n",
        "    # Adjust for the correct argument or truncate results manually\n",
        "      try:\n",
        "          results = self.vector_store.similarity_search(query=paper_summary)  # Remove `top_k`\n",
        "        # Limit results manually\n",
        "          results = results[:3] if len(results) > 3 else results\n",
        "          return [result for result in results if target_conference in result.page_content]\n",
        "      except Exception as e:\n",
        "          print(f\"Error during similarity search: {e}\")\n",
        "          return []\n",
        "\n",
        "    def discuss_and_decide(self, paper_summary: str) -> Dict:\n",
        "      evaluations = []\n",
        "\n",
        "    # Loop through each agent to perform context retrieval and paper evaluation\n",
        "      for agent in self.agents:\n",
        "            try:\n",
        "                # Retrieve conference-specific context\n",
        "                relevant_context = agent.retrieve_conference_context(paper_summary)\n",
        "\n",
        "                # Combine paper summary with retrieved context\n",
        "                augmented_summary = f\"{paper_summary}\\n\\nRelated Contexts:\\n{relevant_context}\"\n",
        "\n",
        "                # Evaluate the paper using the agent\n",
        "                evaluation = agent.evaluate_paper(augmented_summary)\n",
        "\n",
        "                # Append the evaluation to the list\n",
        "                evaluations.append({\n",
        "                    \"conference\": agent.target_conference,\n",
        "                    \"score\": evaluation.get(\"score\", 0),\n",
        "                    \"justification\": evaluation.get(\"justification\", \"No justification provided.\")\n",
        "                })\n",
        "\n",
        "            except Exception as e:\n",
        "                # Handle any errors during context retrieval or evaluation\n",
        "                print(f\"Error evaluating paper for {agent.target_conference}: {e}\")\n",
        "                evaluations.append({\n",
        "                    \"conference\": agent.target_conference,\n",
        "                    \"score\": 0,\n",
        "                    \"justification\": f\"Failed to evaluate paper due to: {e}\"\n",
        "                })\n",
        "\n",
        "        # Determine the best conference based on scores\n",
        "\n",
        "      best_conference = max(evaluations, key=lambda x: x[\"score\"]  if x[\"score\"] is not None else -1)\n",
        "\n",
        "        # Store evaluations in the vector store for future reference\n",
        "      for evaluation in evaluations:\n",
        "            self.store_evaluation(paper_summary, evaluation)\n",
        "\n",
        "        # Return the best conference and justification\n",
        "      return {\n",
        "            \"best_conference\": best_conference[\"conference\"],\n",
        "            \"justification\": best_conference[\"justification\"]\n",
        "        }\n",
        "\n",
        "    def store_evaluation(self, paper_summary: str, evaluation: Dict):\n",
        "        \"\"\"Store evaluations in a local JSON file if vector store doesn't support additions.\"\"\"\n",
        "        metadata = {\n",
        "            \"best_conference\": evaluation.get(\"conference\", \"Unknown\"),\n",
        "            \"justification\": evaluation.get(\"justification\", \"No justification provided.\"),\n",
        "            \"score\": evaluation.get(\"score\", 0),\n",
        "        }\n",
        "        try:\n",
        "            # Save evaluations locally\n",
        "            with open(\"evaluations.json\", \"a\") as f:\n",
        "                json.dump({\"text\": paper_summary, \"metadata\": metadata}, f)\n",
        "                f.write(\"\\n\")\n",
        "            print(\"Evaluation stored locally.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error storing evaluation locally: {e}\")\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    chat_model = ChatGroq(groq_api_key = userdata.get(\"GROQ_API_KEY\").strip(), model=\"llama-3.1-8b-instant\")\n",
        "    # Define agents for each conference\n",
        "    agents = [\n",
        "        ConferenceAgent(name=\"Agent CVPR\", chat_model=chat_model, target_conference=\"CVPR\",\n",
        "                        conference_themes = \"\"\"\n",
        "                        CVPR focuses on the field of computer vision, image processing, and pattern recognition. Key themes include:\n",
        "                          Object detection and recognition.\n",
        "                          Image segmentation and scene understanding.\n",
        "                          Visual tracking and motion analysis.\n",
        "                          3D vision, stereo vision, and depth estimation.\n",
        "                          Deep learning for vision tasks (CNNs, Vision Transformers, etc.).\n",
        "                          Applications in medical imaging, autonomous vehicles, and robotics.\n",
        "                          Video processing and understanding.\n",
        "                          Computational photography and imaging.\n",
        "                          Low-level vision (denoising, super-resolution).\n",
        "                          Vision-based augmented reality and virtual reality.\n",
        "                        \"\"\",\n",
        "                        conference_context = \"\"\"\n",
        "                        Examples of accepted papers:\n",
        "                          - YOLO: Real-Time Object Detection\n",
        "                              Summary: Proposes an efficient deep learning model for real-time object detection with state-of-the-art accuracy.\n",
        "                          - SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation\n",
        "                              Summary: Focuses on pixel-wise image segmentation using deep neural networks, with applications in autonomous systems.\n",
        "                          - 3D Object Detection and Localization Using RGB and Depth Data\n",
        "                              Summary: Combines RGB and depth information for accurate 3D object detection in indoor environments.\n",
        "                        Evaluation Criteria:\n",
        "                         - Relevance to core computer vision topics.\n",
        "                         - Advances in methodology or application.\n",
        "                         - Practical implications for industries like healthcare, robotics, and transportation.\n",
        "                        \"\"\", vectorstore=client\n",
        "                        ),\n",
        "        ConferenceAgent(name=\"Agent NeurIPS\", chat_model=chat_model, target_conference=\"NeurIPS\"\n",
        "                        ,conference_themes =\"\"\"\n",
        "                        NeurIPS emphasizes machine learning, computational neuroscience, and AI-related topics. Key themes include:\n",
        "                            Deep learning (e.g., architectures, generative models, optimization for deep networks, foundation models, LLMs)\n",
        "                            Reinforcement learning and decision-making.\n",
        "                            Probabilistic models and Bayesian learning.\n",
        "                            Optimization techniques for machine learning.\n",
        "                            Representation learning and embeddings.\n",
        "                            AI for healthcare, climate science, and sustainability.\n",
        "                            Neuroscience-inspired algorithms and theories.\n",
        "                            Ethical AI, fairness, and explainability.\n",
        "                        \"\"\",\n",
        "                        conference_context = \"\"\"\n",
        "                        Examples of accepted papers:\n",
        "                          - Attention Is All You Need\n",
        "                             Summary: Introduces the transformer architecture, which revolutionized NLP and other domains by using self-attention mechanisms.\n",
        "                          - Generative Adversarial Networks (GANs)\n",
        "                             Summary: Proposes a novel framework for training generative models using adversarial networks.\n",
        "                          - Adam: A Method for Stochastic Optimization\n",
        "                             Summary: Proposes a new optimization algorithm that balances convergence speed and stability in deep learning.\n",
        "                        Evaluation Criteria:\n",
        "                          - Novelty and theoretical contributions.\n",
        "                          - Experimental rigor and reproducibility.\n",
        "                          - Broader implications for machine learning and interdisciplinary applications.\n",
        "                        \"\"\",\n",
        "                        vectorstore=client\n",
        "        ),\n",
        "        ConferenceAgent(name=\"Agent EMNLP\", chat_model=chat_model, target_conference=\"EMNLP\"\n",
        "                        ,conference_themes = \"\"\"\n",
        "                        EMNLP specializes in NLP and computational linguistics. Key themes include:\n",
        "                          Machine translation and cross-lingual NLP.\n",
        "                          Large language models and foundational models.\n",
        "                          Sentiment analysis and opinion mining.\n",
        "                          Dialogue systems and conversational AI.\n",
        "                          Question answering and information retrieval.\n",
        "                          Text summarization and abstraction.\n",
        "                          Morphology, syntax, and semantics.\n",
        "                          Multimodal NLP (text + image/audio fusion).\n",
        "                          Ethical concerns in NLP (bias, toxicity detection).\n",
        "                          Low-resource and multilingual NLP.\n",
        "                        \"\"\",\n",
        "                        conference_context = \"\"\"\n",
        "                        Examples of accepted papers:\n",
        "\n",
        "Paper Title: Pre-trained Language Models for Text-to-Text Generation\n",
        "Summary: This paper explores pre-trained models (e.g., T5) for a variety of text-to-text NLP tasks, showcasing improvements across summarization, question answering, and translation.\n",
        "\n",
        "Paper Title: Adversarial Training for Robust Text Classification\n",
        "Summary: Proposes an adversarial training framework that enhances the robustness of text classification models against noisy and adversarial inputs.\n",
        "\n",
        "Paper Title: Knowledge-Enhanced Contextual Representations for Entity Linking\n",
        "Summary: Combines external knowledge sources with contextual embeddings to improve entity linking in complex domains.\n",
        "\n",
        "Paper Title: Multimodal Sentiment Analysis with Attention Mechanisms\n",
        "Summary: Introduces a framework for combining visual and textual inputs to improve sentiment detection in videos.\n",
        "\n",
        "Evaluation Criteria:\n",
        "Relevance to NLP:\n",
        "\n",
        "Papers should directly address core NLP tasks, methodologies, or applications.\n",
        "Emphasis on empirical evaluation and innovation in language processing methods.\n",
        "Quality of Methodology:\n",
        "\n",
        "Rigorous experiments, proper baselines, and thorough ablation studies.\n",
        "Use of diverse and large-scale datasets to validate results.\n",
        "Novelty of Contribution:\n",
        "\n",
        "New architectures, algorithms, or findings that advance the field.\n",
        "Extensions of existing methods to novel tasks or domains.\n",
        "Broader Impacts:\n",
        "\n",
        "Ethical implications of the research (e.g., bias in models, data privacy).\n",
        "Potential for cross-disciplinary applications (e.g., in healthcare, education, or social media).\n",
        "Themes Breakdown with Examples:\n",
        "Natural Language Understanding:\n",
        "\n",
        "Semantic role labeling, coreference resolution, and discourse parsing.\n",
        "Example: A New Framework for Semantic Parsing Using Pre-Trained Transformers.\n",
        "Language Generation:\n",
        "\n",
        "Dialogue systems, machine translation, and creative text generation.\n",
        "Example: Controlled Text Generation with Discrete and Continuous Latent Variables.\n",
        "Information Extraction:\n",
        "\n",
        "Named entity recognition, relation extraction, and knowledge graph construction.\n",
        "Example: Joint Entity and Relation Extraction with Transformer-Based Models.\n",
        "Multimodal NLP:\n",
        "\n",
        "Integrating vision, audio, and textual modalities.\n",
        "Example: Aligning Text and Vision for Multimodal Machine Translation.\n",
        "Social and Ethical Considerations:\n",
        "\n",
        "Bias, fairness, interpretability, and environmental impacts of NLP models.\n",
        "Example: Bias Mitigation in Pre-trained Models: A Data Augmentation Approach.\n",
        "\n",
        "                        \"\"\",\n",
        "                        vectorstore=client\n",
        "\n",
        "        ),\n",
        "        ConferenceAgent(name=\"Agent KDD\", chat_model=chat_model, target_conference=\"KDD\"\n",
        "                        ,conference_themes = \"\"\"\n",
        "                        KDD centers on data mining, big data, and applied AI. Key themes include:\n",
        "                            Scalable data mining algorithms.\n",
        "                            Graph data and network analysis.\n",
        "                            Temporal and sequential data mining.\n",
        "                            Anomaly detection and predictive modeling.\n",
        "                            Recommender systems and personalization.\n",
        "                            Causal inference and counterfactual reasoning.\n",
        "                            Applications in finance, e-commerce, and marketing.\n",
        "                            Data visualization and interpretability.\n",
        "                            Data ethics and privacy-preserving techniques.\n",
        "                            AI and data-driven solutions for social good.\n",
        "                        \"\"\",\n",
        "\n",
        "                        conference_context=\"\"\"\n",
        "                        Examples of accepted papers:\n",
        "\n",
        "Paper Title: Scalable Graph Neural Networks for Large-Scale Social Network Analysis\n",
        "Summary: Introduces a scalable GNN framework that handles billion-scale graphs with high efficiency, showcasing applications in social network analysis.\n",
        "\n",
        "Paper Title: Causal Discovery in High-Dimensional Data Using Deep Learning\n",
        "Summary: Proposes a deep learning-based approach for identifying causal relationships in high-dimensional data.\n",
        "\n",
        "Paper Title: Fair Representation Learning with Adversarial Networks\n",
        "Summary: Develops a framework for learning fair data representations while minimizing demographic bias in downstream tasks.\n",
        "\n",
        "Paper Title: Adaptive Online Learning for Real-Time Recommender Systems\n",
        "Summary: Presents an adaptive online learning algorithm that updates recommender system models in real time based on user interactions.\n",
        "\n",
        "Evaluation Criteria:\n",
        "Relevance to Knowledge Discovery and Data Mining:\n",
        "\n",
        "Papers must address core challenges in data mining, machine learning, or related applications.\n",
        "Emphasis on practical applications and scalability to real-world data.\n",
        "Methodological Rigor:\n",
        "\n",
        "Strong theoretical foundations or innovative empirical methodologies.\n",
        "Comprehensive experiments with real-world datasets and benchmarks.\n",
        "Scalability and Efficiency:\n",
        "\n",
        "Solutions must handle large-scale data effectively, both in computation and memory.\n",
        "Novelty and Impact:\n",
        "\n",
        "New techniques, algorithms, or applications that significantly advance the state-of-the-art.\n",
        "Real-world relevance and potential societal or economic impact.\n",
        "Broader Implications:\n",
        "\n",
        "Ethical considerations, such as fairness, transparency, and responsible use of data.\n",
        "Long-term applicability across industries and domains.\n",
        "                        \"\"\",\n",
        "                        vectorstore=client\n",
        "        ),\n",
        "    ]\n",
        "\n",
        "    storm_system = STORMSystem(agents=agents,vectorstore=client)\n",
        "\n",
        "    # Input a research paper summary\n",
        "    paper_summary = \"\"\"\n",
        "\n",
        "output=PaperEvaluation(significance=\"Here are five detailed points summarizing the significance of the research:\\n\\n1. Addressing Plasticity Loss in Deep Reinforcement Learning: The research aims to tackle a critical issue in deep reinforcement learning, plasticity loss, which results in a decline in an agent's performance over time. By proposing a novel approach called 'plasticity injection,' the study has the potential to improve the long-term performance and adaptability of RL agents in dynamic environments.\\n\\n2. Improving Robustness and Reliability: The proposed method, plasticity injection, offers a diagnostic framework and a mitigation strategy to maintain consistent performance over extended training periods without incurring significant computational demands. This contribution has the potential to improve the robustness and reliability of RL agents in complex and dynamic environments.\\n\\n3. Enhancing Efficiency and Effectiveness: The targeted approach to selectively modify the network's internal dynamics without altering its overall architecture could improve the efficiency and effectiveness of RL agents in dynamic environments. Additionally, the use of a diagnostic framework to trigger resource allocation adds a layer of efficiency and adaptability to the method.\\n\\n4. Impact on Real-World Applications: The research has the potential to impact various areas of artificial intelligence, including robotics, computer vision, and natural language processing, where RL agents are increasingly being deployed. The proposed method could significantly improve the performance and adaptability of intelligent systems, making it a valuable contribution to the field.\\n\\n5. Potential to Advance State-of-the-Art in RL: The novel approach to dynamically adjusting artificial neural networks to maintain learning capacity over time could advance the state-of-the-art in reinforcement learning, particularly in complex real-world scenarios. The modular design of the framework allows for easy integration with various RL algorithms and architectures, making it a versatile tool for a wide range of applications. Here are the 5 detailed points summarizing the significance:\\n\\n1. Potential Impact on Artificial General Intelligence: This research has the potential to impact the field of artificial general intelligence, particularly in addressing the challenges of catastrophic forgetting. The novel contribution of dynamic capacity allocation in Reinforcement Learning (RL) agents with plasticity injection can enable agents to adapt to changing environments and tasks, advancing the state-of-the-art in RL.\\n\\n2. Improving Long-Term Performance and Learning Stability: The proposed approach aims to mitigate plasticity loss and improve the long-term performance and learning stability of RL agents. This is achieved through the injection of plasticity, which allows agents to adapt to changing environments and tasks, leading to improved performance and computational efficiency.\\n\\n3. Value in Practical Application and Field of RL: The paper's significance lies in its practical application and potential impact on the field of RL. The framework's modularity and computational efficiency enable it to adapt to different RL tasks and environments, achieving consistent improvement in long-term performance and learning stability.\\n\\n4. Contribution to Understanding Lifelong Learning in AI: This research explores the impact of plasticity injection on artificial agents, contributing to the understanding of lifelong learning in artificial intelligence. The study sheds light on the importance of individual components of the plasticity injection framework, providing a deeper understanding of their interplay.\\n\\n5. Potential to Benefit Broader Field of Reinforcement Learning: The paper's findings have the potential to benefit the broader field of reinforcement learning, as the proposed method is applicable to a diverse set of challenging RL environments, including continuous control tasks and partially observable Markov decision processes (POMDPs).\n",
        "\n",
        "\n",
        "The results can also be used to inform the design of more efficient and effective plasticity injection frameworks.\", methodology=\"1. Research Question and Objectives: The researchers aim to address the problem of plasticity loss in deep neural networks, with the objective of proposing a novel intervention called 'plasticity injection' to tackle this issue.\\n\\n2. Methodology: The proposed plasticity injection method involves a dynamic expansion mechanism triggered by a diagnostic framework, which is designed to selectively modify the network's internal dynamics and maintain computational efficiency while preventing performance degradation.\\n\\n3. Experimental Design: The researchers employed a rigorous experimental setup, including the use of RL benchmarks and comparison with state-of-the-art baselines, to evaluate the effectiveness of the plasticity injection framework. The evaluation metrics used include long-term performance, learning stability, and computational efficiency.\\n\\n4. Evaluation and Comparison: The researchers conducted ablation studies to systematically analyze the contributions of individual components to overall performance improvement. The study also employed statistical tests, including paired t-tests, to determine the statistical significance of performance differences between agents with and without plasticity injection.\\n\\n5. Contributions and Limitations: The proposed plasticity injection method is a novel approach to addressing plasticity loss in deep neural networks, and the study provides a comprehensive evaluation of its effectiveness across diverse RL environments. However, the paper could benefit from more detailed explanations of the diagnostic framework, mitigation strategy, and experimental design, as well as a more detailed discussion of the experimental results and the choice of evaluation metrics.\", presentation=\"1. Improvement of Introduction and Related Work Section: To enhance the reader's understanding and appreciation of the research, it is recommended to provide more detailed background information on the problem and existing approaches. This can include a more comprehensive introduction, a stronger connection to related work, and additional context to facilitate understanding.\\n\\n2. Increased Use of Visual Aids: To make the paper more engaging and easier to understand, it is suggested to incorporate more visual aids, such as diagrams, flowcharts, tables, and figures, to illustrate the proposed approach, its components, and the results.\\n\\n3. Enhanced Clarity and Conciseness: To improve the paper's clarity and conciseness, it is recommended to use simpler language, provide more concrete examples, and avoid overly formal or technical jargon. Additionally, providing more detailed explanations and examples in sections such as the related work and methodology can facilitate understanding.\\n\\n4. More Context and Background Information: To make the paper more accessible to readers unfamiliar with the topic, it is suggested to provide more context and background information on the problem domain and the plasticity injection framework. This can include a more detailed introduction to the background and context of the research.\\n\\n5. Increased Use of Specific Examples and Visual Aids: To help illustrate the key points, it is recommended to incorporate more specific examples and visual aids, such as figures and tables, to make the text more engaging and easier to understand. This can also help to facilitate understanding of the results and the proposed approach.\", confidence_score=7.774193548387097, score=7.53548387096774, major_strengths=\"Here are the 5 detailed points summarizing the major strengths of the research:\\n\\n1. Novel and Effective Approach to Plasticity Loss: The research proposes a novel and efficient approach, 'plasticity injection,' to address a significant problem in deep reinforcement learning, offering a proactive diagnostic framework and targeted intervention to prevent plasticity loss in RL agents.\\n\\n2.\n",
        "\n",
        "Preservation of Prediction Capabilities and Selective Modification of Network Dynamics: The approach successfully maintains consistent performance without incurring significant computational demands, and selectively modifies the network's internal dynamics rather than its overall architecture, ensuring that the prediction capabilities of the network are preserved.\\n\\n3. Comprehensive Evaluation and Comparison with Existing Approaches: The research presents a thorough evaluation and comparison with existing approaches, using well-established evaluation metrics, and demonstrates the effectiveness of the proposed method in mitigating plasticity loss through comprehensive experimental results.\\n\\n4. Modular Design, Computational Efficiency, and Adaptability: The proposed plasticity injection framework is designed to be modular, allowing for easy integration with various RL algorithms and architectures, and is computationally efficient and scalable, making it a valuable tool for enhancing the robustness and longevity of RL agents.\\n\\n5. Clear Presentation, Logical Flow of Ideas, and Practical Implications: The paper presents a clear and well-organized argument, making it easy to follow and understand, and highlights the practical implications of the research, including improved adaptability and applicability of RL agents, and the potential to benefit the broader field of reinforcement learning.\", major_weaknesses=\"Here are the 5 major weaknesses of the paper:\\n\\n1. Lack of detailed explanations and empirical evaluations: The paper lacks detailed explanations of the proposed method, its underlying mechanisms, and its efficiency and scalability. Additionally, the evaluation of the proposed approach is limited to a single experiment, which may not be sufficient to demonstrate its effectiveness.\\n\\n2. Insufficient connections to existing research and limited scope: The paper could benefit from more explicit connections to existing research in the field, a stronger introduction that provides specific details on the methodology and background information, and a more comprehensive evaluation of its generalizability.\\n\\n3. Limited discussion of potential limitations and challenges: The paper does not discuss the potential limitations and challenges of the proposed approach, which may hinder its applicability to real-world scenarios.\\n\\n4. Lack of detailed implementation and evaluation details: The paper lacks detailed implementation and evaluation details, making it difficult to fully assess the proposed approach. Additionally, the reliance on existing RL environments and frameworks limits the novelty of the contribution.\\n\\n5. Limited novelty and scope of evaluation metrics: The paper's novelty is somewhat limited by its reliance on existing techniques, and the evaluation metrics used may not capture the full range of potential benefits and drawbacks of the plasticity injection method. The paper could benefit from more comprehensive evaluation and comparison with existing methods, as well as a more detailed description of the experimental design and parameters.\", justification=\"Here are the detailed points for the justification string:\\n\\n1. Clear and concise writing style: The paper's writing style is clear and concise, making it easy to understand and follow. This is a significant strength, as it allows readers to quickly grasp the main points of the research.\\n\\n2. Potential impact on the field: The paper has the potential to make a significant contribution to the field of Reinforcement Learning (RL), with its novel approach to addressing plasticity loss. This potential impact is a major factor in the overall score.\\n\\n3. Lack of detailed explanations and empirical evaluations: Despite the paper's potential impact, there is a lack of detailed explanations and empirical evaluations to further validate the effectiveness of the proposed method. This is a significant weakness, as it reduces the research's rigor and reproducibility.\\n\\n4.\n",
        "\n",
        "Well-defined methodology and presentation: The paper's methodology is well-defined, and the presentation is clear and well-organized. This is a major strength, as it allows readers to easily follow the research and understand the results.\\n\\n5. Need for further refinement and detail: While the paper shows promise, it could benefit from additional details on the experimental setup, theoretical underpinnings, and practical applications to further strengthen its impact and reproducibility.\", detailed_feedback=\"1. Enhance Introduction and Methodology: The researchers should provide a more detailed introduction explaining the significance and relevance of the research, proposed method, and its differences from existing approaches. A clear and concise methodology section should be included to provide a better understanding of the research.\\n\\n2. Provide Context and Background Information: The authors should provide more context on the problem and existing approaches, describe the proposed intervention in detail, and discuss the expected efficiency and adaptability of their solution. A background information section on the research question, literature review, and theoretical framework would enhance the paper's significance and impact.\\n\\n3. Validate Novel Metrics and Approach: The authors should provide more details on the derivation and validation of novel metrics used to capture subtle changes in network behavior. A more comprehensive evaluation of the proposed approach, including multiple experiments and comparisons to state-of-the-art methods, would be beneficial.\\n\\n4. Discuss Potential Limitations and Future Directions: The authors should discuss the potential limitations of their approach and potential areas for future research. They could also explore the integration of plasticity injection with other RL algorithms and architectures to further demonstrate its versatility and potential.\\n\\n5. Improve Writing Style and Reproducibility: The paper would benefit from a more detailed discussion of the potential real-world applications and limitations of the approach. The authors should provide more details on the experimental design, sample size, and agent architectures to enhance the reproducibility of the results.\", publishable=True)\n",
        "\"\"\"\n",
        "    decision = storm_system.discuss_and_decide(paper_summary)\n",
        "    print(f\"Best Conference: {decision['best_conference']}\")\n",
        "    print(f\"Justification: {decision['justification']}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain langchain_community langgraph langchain_groq langchain_huggingface pathway"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZ76QDxNzI2L",
        "outputId": "8ec97523-fbe8-4978-fb72-9262c414afc9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.14)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.14-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.2.61-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting langchain_groq\n",
            "  Downloading langchain_groq-0.2.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain_huggingface\n",
            "  Downloading langchain_huggingface-0.1.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting pathway\n",
            "  Downloading pathway-0.16.4-cp310-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.11)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.29)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.4)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.10)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.4 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.9-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.51-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting groq<1,>=0.4.1 (from langchain_groq)\n",
            "  Downloading groq-0.14.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (0.27.1)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (3.3.1)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (0.21.0)\n",
            "Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (4.47.1)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (8.1.8)\n",
            "Requirement already satisfied: geopy>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.4.1)\n",
            "Collecting h3>=4 (from pathway)\n",
            "  Downloading h3-4.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.6.0)\n",
            "Requirement already satisfied: shapely>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.0.6)\n",
            "Collecting sqlglot==10.6.1 (from pathway)\n",
            "  Downloading sqlglot-10.6.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: pyarrow>=10.0.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (17.0.0)\n",
            "Collecting python-sat>=0.1.8.dev0 (from pathway)\n",
            "  Downloading python_sat-1.8.dev14-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting beartype<0.16.0,>=0.14.0 (from pathway)\n",
            "  Downloading beartype-0.15.0-py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (13.9.4)\n",
            "Collecting diskcache>=5.2.1 (from pathway)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: exceptiongroup>=1.1.3 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.2.2)\n",
            "Collecting boto3>=1.26.76 (from pathway)\n",
            "  Downloading boto3-1.35.96-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: google-api-python-client>=2.108.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.155.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (4.12.2)\n",
            "Requirement already satisfied: panel>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.5.5)\n",
            "Collecting jupyter-bokeh>=3.0.7 (from pathway)\n",
            "  Downloading jupyter_bokeh-4.0.5-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jmespath>=1.0.1 (from pathway)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting aiohttp-cors>=0.7.0 (from pathway)\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.29.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.22.0 (from pathway)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting fs>=2.4.16 (from pathway)\n",
            "  Downloading fs-2.4.16-py2.py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting async-lru>=2.0.4 (from pathway)\n",
            "  Downloading async_lru-2.0.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: networkx>=3.2.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (3.4.2)\n",
            "Requirement already satisfied: google-cloud-pubsub>=2.21.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.27.1)\n",
            "Requirement already satisfied: google-cloud-bigquery in /usr/local/lib/python3.10/dist-packages (from pathway) (3.25.0)\n",
            "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
            "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython>=3.1.43 in /usr/local/lib/python3.10/dist-packages (from pathway) (3.1.44)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Collecting botocore<1.36.0,>=1.35.96 (from boto3>=1.26.76->pathway)\n",
            "  Downloading botocore-1.35.96-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3>=1.26.76->pathway)\n",
            "  Downloading s3transfer-0.10.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.25.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting appdirs~=1.4.3 (from fs>=2.4.16->pathway)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from fs>=2.4.16->pathway) (75.1.0)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.10/dist-packages (from fs>=2.4.16->pathway) (1.17.0)\n",
            "Requirement already satisfied: geographiclib<3,>=1.52 in /usr/local/lib/python3.10/dist-packages (from geopy>=2.4.0->pathway) (2.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython>=3.1.43->pathway) (4.0.12)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.108.0->pathway) (0.22.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.108.0->pathway) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.108.0->pathway) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.108.0->pathway) (2.19.2)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.108.0->pathway) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.51.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (1.69.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (1.25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (4.25.5)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (0.14.0)\n",
            "Requirement already satisfied: grpcio-status>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (1.62.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (24.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.67.1)\n",
            "Requirement already satisfied: bokeh==3.* in /usr/local/lib/python3.10/dist-packages (from jupyter-bokeh>=3.0.7->pathway) (3.6.2)\n",
            "Collecting ipywidgets==8.* (from jupyter-bokeh>=3.0.7->pathway)\n",
            "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (3.1.5)\n",
            "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (1.3.1)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (11.1.0)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (6.3.3)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (2024.9.0)\n",
            "Collecting comm>=0.1.3 (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.12 (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway)\n",
            "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (3.0.13)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (1.33)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.4->langgraph) (1.1.0)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.13)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.22.0->pathway) (1.2.15)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.22.0->pathway) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.22.0->pathway) (1.66.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.22.0->pathway)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.22.0->pathway)\n",
            "  Downloading opentelemetry_proto-1.29.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 (from google-cloud-pubsub>=2.21.1->pathway)\n",
            "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk>=1.22.0->pathway) (0.50b0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1->pathway) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1->pathway) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1->pathway) (2024.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (6.2.0)\n",
            "Requirement already satisfied: linkify-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (2.0.3)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (3.7)\n",
            "Requirement already satisfied: markdown-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (3.0.0)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (0.4.2)\n",
            "Requirement already satisfied: param<3.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (2.2.0)\n",
            "Requirement already satisfied: pyviz-comms>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (3.0.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Collecting pydantic-core==2.23.4 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
            "  Downloading pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->pathway) (2.18.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->pathway) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->pathway) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->pathway) (3.5.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (2.5.1+cu121)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain_huggingface) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain_huggingface) (0.5.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery->pathway) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery->pathway) (2.7.2)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api>=1.22.0->pathway) (1.17.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.43->pathway) (5.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=2.108.0->pathway) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=2.108.0->pathway) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=2.108.0->pathway) (4.9)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery->pathway) (1.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client>=2.108.0->pathway) (3.2.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.14.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.22.0->pathway) (3.21.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py->panel>=1.3.1->pathway) (0.1.2)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.3.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->panel>=1.3.1->pathway) (0.5.1)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py->panel>=1.3.1->pathway) (1.0.3)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (3.0.48)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.9->bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=2.108.0->pathway) (0.6.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.2.13)\n",
            "Downloading langchain_community-0.3.14-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-0.2.61-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.2/137.2 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_groq-0.2.3-py3-none-any.whl (14 kB)\n",
            "Downloading langchain_huggingface-0.1.2-py3-none-any.whl (21 kB)\n",
            "Downloading pathway-0.16.4-cp310-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sqlglot-10.6.1-py3-none-any.whl (223 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.4/223.4 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Downloading async_lru-2.0.4-py3-none-any.whl (6.1 kB)\n",
            "Downloading beartype-0.15.0-py3-none-any.whl (777 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m777.6/777.6 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.35.96-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fs-2.4.16-py2.py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groq-0.14.0-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h3-4.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (993 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.5/993.5 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading jupyter_bokeh-4.0.5-py3-none-any.whl (148 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.6/148.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.9-py3-none-any.whl (37 kB)\n",
            "Downloading langgraph_sdk-0.1.51-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.29.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.9/434.9 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
            "Downloading python_sat-1.8.dev14-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_28_x86_64.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading botocore-1.35.96-py3-none-any.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.25.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading s3transfer-0.10.4-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sqlglot, appdirs, widgetsnbextension, python-sat, python-dotenv, pydantic-core, protobuf, mypy-extensions, marshmallow, jmespath, jedi, httpx-sse, h3, fs, diskcache, comm, beartype, async-lru, typing-inspect, pydantic, opentelemetry-proto, botocore, s3transfer, pydantic-settings, opentelemetry-exporter-otlp-proto-common, langgraph-sdk, ipywidgets, groq, dataclasses-json, jupyter-bokeh, boto3, aiohttp-cors, opentelemetry-exporter-otlp-proto-grpc, langgraph-checkpoint, langchain_groq, pathway, langgraph, langchain_huggingface, langchain_community\n",
            "  Attempting uninstall: sqlglot\n",
            "    Found existing installation: sqlglot 25.1.0\n",
            "    Uninstalling sqlglot-25.1.0:\n",
            "      Successfully uninstalled sqlglot-25.1.0\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.10\n",
            "    Uninstalling widgetsnbextension-3.6.10:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.10\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.27.2\n",
            "    Uninstalling pydantic_core-2.27.2:\n",
            "      Successfully uninstalled pydantic_core-2.27.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.10.4\n",
            "    Uninstalling pydantic-2.10.4:\n",
            "      Successfully uninstalled pydantic-2.10.4\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 1.30.0 requires sqlglot<25.2,>=23.6.3, but you have sqlglot 10.6.1 which is incompatible.\n",
            "ibis-framework 9.2.0 requires sqlglot<25.7,>=23.4, but you have sqlglot 10.6.1 which is incompatible.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.3 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiohttp-cors-0.7.0 appdirs-1.4.4 async-lru-2.0.4 beartype-0.15.0 boto3-1.35.96 botocore-1.35.96 comm-0.2.2 dataclasses-json-0.6.7 diskcache-5.6.3 fs-2.4.16 groq-0.14.0 h3-4.1.2 httpx-sse-0.4.0 ipywidgets-8.1.5 jedi-0.19.2 jmespath-1.0.1 jupyter-bokeh-4.0.5 langchain_community-0.3.14 langchain_groq-0.2.3 langchain_huggingface-0.1.2 langgraph-0.2.61 langgraph-checkpoint-2.0.9 langgraph-sdk-0.1.51 marshmallow-3.25.0 mypy-extensions-1.0.0 opentelemetry-exporter-otlp-proto-common-1.29.0 opentelemetry-exporter-otlp-proto-grpc-1.29.0 opentelemetry-proto-1.29.0 pathway-0.16.4 protobuf-5.29.3 pydantic-2.9.2 pydantic-core-2.23.4 pydantic-settings-2.7.1 python-dotenv-1.0.1 python-sat-1.8.dev14 s3transfer-0.10.4 sqlglot-10.6.1 typing-inspect-0.9.0 widgetsnbextension-4.0.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade langgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCvMvqsQzRVv",
        "outputId": "5c6f10c6-0f6a-45da-c0a6-5f96c2a564fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.10/dist-packages (0.2.61)\n",
            "Requirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in /usr/local/lib/python3.10/dist-packages (from langgraph) (0.3.29)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from langgraph) (2.0.9)\n",
            "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /usr/local/lib/python3.10/dist-packages (from langgraph) (0.1.48)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.33)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.2.3)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (24.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.10.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (4.12.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.4->langgraph) (1.1.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.10/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.12)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.2.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pathway connector\n",
        "from langchain_community.vectorstores import PathwayVectorClient\n",
        "\n",
        "client = PathwayVectorClient(url=\"https://demo-document-indexing.pathway.stream\")\n"
      ],
      "metadata": {
        "id": "bQ8yAHhz1Kd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is Pathway?\"\n",
        "docs = client.similarity_search(query, timeout=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYRycdCSOYxR",
        "outputId": "49aa1719-8fcd-4249-a2fb-8e098a7bb337"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Unknown kwargs passed to PathwayVectorClient.similarity_search: {'timeout': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "YFJ8abidOtbb",
        "outputId": "25ed5e92-0eba-4c4b-aef8-7fde1f64ad59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3 2 0 2\\nl u J\\n2 1\\n]\\nG L . s c [\\n1 v 6 1 1 3 1 . 7 0 3 2 : v i X r a\\nPathway: a fast and flexible unified stream data processing framework for analytical and Machine Learning applications\\nMichał Bartoszkiewicz\\nJan Chorowski∗\\nAdrian Kosowski\\nJakub Kowalski\\nSergey Kulik\\nMateusz Lewandowski\\nKrzysztof Nowicki\\nKamil Piechowiak\\nOlivier Ruas\\nZuzanna Stamirowska\\nPrzemysław Uznański\\n{firstname.lastname}@pathway.com Pathway.com Paris, France\\nABSTRACT We present Pathway, a new unified data processing framework that can run workloads on both bounded and unbounded data streams. The framework was created with the original motivation of re- solving challenges faced when analyzing and processing data from the physical economy, including streams of data generated by IoT and enterprise systems. These required rapid reaction while calling for the application of advanced computation paradigms (machine- learning-powered analytics, contextual analysis, and other elements of complex event processing). Pathway is equipped with a Table API tailored for Python and Python/SQL workflows, and is pow- ered by a distributed incremental dataflow in Rust. We describe the system and present benchmarking results which demonstrate its capabilities in both batch and streaming contexts, where it is able to surpass state-of-the-art industry frameworks in both scenarios. We also discuss streaming use cases handled by Pathway which cannot be easily resolved with state-of-the-art industry frameworks, such as streaming iterative graph algorithms (PageRank, etc.).\\nCCS CONCEPTS • Information systems → Computing platforms; Data stream- ing; Location based services.\\nKEYWORDS Event streaming, Batch computation, Incremental computation, Pathway, Benchmark.\\n1 INTRODUCTION Traditionally, data processing systems were designed either for high throughput batch computations, or for low latency streaming processing. However, modern data applications often demand low latencies at high data throughputs. One solution is the lambda architecture [20], which calls for running two similar workloads: a batch one for exact computations on historical data and a streaming one used to patch the batch results with latest data. Alternatively, aiming to avoid architecture complexity, it is also possible to rely on data processing frameworks which unify batch and streaming computations.\\nThe new data processing framework which we describe in this paper, Pathway, has a unified runtime suitable for running both streaming and batch tasks. Its design results from the need to per- form certain types of real-time analytics workloads, which we con- sidered in the logistics and supply chain vertical (see Section 2) but arguably representative of a wider range of industry data. These workloads call for a contextual data analysis, sometimes entering into the real-time machine learning space, in addition to giving significant attention to out-of-order data point arrival in event streams. They also typically require the reconciliation of numerous event streams, some of which may carry contradictory (erroneous) information.\\nPathway is a data processing framework with a Python API and a reactive data processing engine with a tunable batch size which allows it to be dynamically adjusted for a desired throughput vs latency trade-off. In this paper, we describe its features and pro- vide benchmark results, comparing Pathway to leading batch and streaming data processing systems on a classical analytical bench- mark, namely a word counting task implemented using groupby, and a fundamental iterative graph processing algorithm, namely PageRank. We demonstrate that Pathway is capable of achieving throughput outperforming state-of-the-art general purpose batch engines, while being able to respond with latencies better than state- of-the-art streaming systems. At the same time, Pathway succeeds in handling in streaming mode types of iterative and contextual workloads, such as PageRank on a changing graph, which to our knowledge are not supported by any generally industrialized system with a Dataframe/Table API programming layer. Overall, the system performance is owed to a combination of design choices around mapping between tabular syntax and actual key-value data orga- nization, the performance of the underlying differential dataflow assembly for key-value data, the designed operator primitives, and inter-operator optimizations made in the transpilation process.\\nThe paper is structured as follows. In Section 2, we outline the original motivation for the creation of Pathway originating from industry use cases. In Section 3, we provide a historical overview of some of the major approaches to dataflow-based streaming data processing. An overview of the Pathway framework, together with code examples, is put forward in Section 4. In Section 5 we provide\\n∗Authors in alphabetical order. Corresponding author: jan.chorowski@pathway.com.\\nPathway team\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from pathway.xpacks.llm.vector_store import VectorStoreServer\n",
        "import os\n",
        "\n",
        "os.environ['HF_TOKEN'] = userdata.get(\"HF_TOKEN\")\n",
        "\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "embeddings = HuggingFaceEmbeddings(model_name='all-MiniLM-L6-v2')\n",
        "\n",
        "\n",
        "import pathway as pw\n",
        "\n",
        "# Example data for table creation\n",
        "data = [\n",
        "    {\"text\": \"This is a test justification.\", \"id\": \"1\"},\n",
        "    {\"text\": \"Another piece of text.\", \"id\": \"2\"}\n",
        "]\n",
        "\n",
        "try:\n",
        "    # Create a Pathway table from records\n",
        "    pathway_table = pw.Table.from_records(\n",
        "        data,\n",
        "        schema=pw.Schema(columns={\n",
        "            \"text\": pw.Column(type=str),\n",
        "            \"id\": pw.Column(type=str)\n",
        "        })\n",
        "    )\n",
        "    print(\"Pathway Table created successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error creating Pathway Table: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0Zf0jA8PC7Q",
        "outputId": "0dd3b0c8-3778-4d6e-ada9-74d779a97ccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error creating Pathway Table: 'super' object has no attribute '__getattr__'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip uninstall pathway"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6DY4yjyQNww",
        "outputId": "86aa56e9-ff6b-40d2-a920-7966a0282558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: pathway 0.16.3\n",
            "Uninstalling pathway-0.16.3:\n",
            "  Would remove:\n",
            "    /usr/local/bin/pathway\n",
            "    /usr/local/lib/python3.10/dist-packages/pathway-0.16.3.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/pathway/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled pathway-0.16.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pathway"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O42s06Y709Hp",
        "outputId": "a10d921c-9028-4b2b-e357-bb959247075d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y\n",
            "Collecting pathway\n",
            "  Using cached pathway-0.16.3-cp310-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "Requirement already satisfied: aiohttp>=3.8.4 in /usr/local/lib/python3.10/dist-packages (from pathway) (3.11.10)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (8.1.7)\n",
            "Requirement already satisfied: geopy>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.4.1)\n",
            "Requirement already satisfied: h3>=4 in /usr/local/lib/python3.10/dist-packages (from pathway) (4.1.2)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.26.4)\n",
            "Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.6.0)\n",
            "Requirement already satisfied: shapely>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.0.6)\n",
            "Requirement already satisfied: sqlglot==10.6.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (10.6.1)\n",
            "Requirement already satisfied: pyarrow>=10.0.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (17.0.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.32.3)\n",
            "Requirement already satisfied: python-sat>=0.1.8.dev0 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.8.dev14)\n",
            "Requirement already satisfied: beartype<0.16.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (0.15.0)\n",
            "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (13.9.4)\n",
            "Requirement already satisfied: diskcache>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (5.6.3)\n",
            "Requirement already satisfied: exceptiongroup>=1.1.3 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.2.2)\n",
            "Requirement already satisfied: boto3>=1.26.76 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.35.93)\n",
            "Requirement already satisfied: google-api-python-client>=2.108.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.155.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (4.12.2)\n",
            "Requirement already satisfied: panel>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.5.4)\n",
            "Requirement already satisfied: jupyter-bokeh>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from pathway) (4.0.5)\n",
            "Requirement already satisfied: jmespath>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.0.1)\n",
            "Requirement already satisfied: aiohttp-cors>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (0.7.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.29.0)\n",
            "Requirement already satisfied: fs>=2.4.16 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.4.16)\n",
            "Requirement already satisfied: async-lru>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.0.4)\n",
            "Requirement already satisfied: networkx>=3.2.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (3.4.2)\n",
            "Requirement already satisfied: google-cloud-pubsub>=2.21.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.27.1)\n",
            "Requirement already satisfied: google-cloud-bigquery in /usr/local/lib/python3.10/dist-packages (from pathway) (3.25.0)\n",
            "Requirement already satisfied: pydantic~=2.9.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.9.2)\n",
            "Requirement already satisfied: gitpython>=3.1.43 in /usr/local/lib/python3.10/dist-packages (from pathway) (3.1.43)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway) (1.18.3)\n",
            "Requirement already satisfied: botocore<1.36.0,>=1.35.93 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.26.76->pathway) (1.35.93)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.26.76->pathway) (0.10.4)\n",
            "Requirement already satisfied: appdirs~=1.4.3 in /usr/local/lib/python3.10/dist-packages (from fs>=2.4.16->pathway) (1.4.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from fs>=2.4.16->pathway) (75.1.0)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.10/dist-packages (from fs>=2.4.16->pathway) (1.17.0)\n",
            "Requirement already satisfied: geographiclib<3,>=1.52 in /usr/local/lib/python3.10/dist-packages (from geopy>=2.4.0->pathway) (2.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython>=3.1.43->pathway) (4.0.11)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.108.0->pathway) (0.22.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.108.0->pathway) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.108.0->pathway) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.108.0->pathway) (2.19.2)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.108.0->pathway) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.51.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (1.68.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (1.25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (5.29.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (0.13.1)\n",
            "Requirement already satisfied: grpcio-status>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (1.62.3)\n",
            "Requirement already satisfied: bokeh==3.* in /usr/local/lib/python3.10/dist-packages (from jupyter-bokeh>=3.0.7->pathway) (3.6.2)\n",
            "Requirement already satisfied: ipywidgets==8.* in /usr/local/lib/python3.10/dist-packages (from jupyter-bokeh>=3.0.7->pathway) (8.1.5)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (3.1.4)\n",
            "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (1.3.1)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (24.2)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (11.0.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (6.0.2)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (6.3.3)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (2024.9.0)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (4.0.13)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (3.0.13)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.22.0->pathway) (1.2.15)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.22.0->pathway) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.22.0->pathway) (1.66.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.29.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.22.0->pathway) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.29.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.22.0->pathway) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk>=1.22.0->pathway) (0.50b0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1->pathway) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1->pathway) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1->pathway) (2024.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (6.2.0)\n",
            "Requirement already satisfied: linkify-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (2.0.3)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (3.7)\n",
            "Requirement already satisfied: markdown-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (3.0.0)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (0.4.2)\n",
            "Requirement already satisfied: param<3.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (2.2.0)\n",
            "Requirement already satisfied: pyviz-comms>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (3.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic~=2.9.0->pathway) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic~=2.9.0->pathway) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->pathway) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->pathway) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->pathway) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->pathway) (2024.12.14)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->pathway) (2.18.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->pathway) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->pathway) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->pathway) (3.5.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery->pathway) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery->pathway) (2.7.2)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api>=1.22.0->pathway) (1.17.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.43->pathway) (5.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=2.108.0->pathway) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=2.108.0->pathway) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=2.108.0->pathway) (4.9)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery->pathway) (1.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client>=2.108.0->pathway) (3.2.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.22.0->pathway) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py->panel>=1.3.1->pathway) (0.1.2)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->panel>=1.3.1->pathway) (0.5.1)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py->panel>=1.3.1->pathway) (1.0.3)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (3.0.48)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.9->bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=2.108.0->pathway) (0.6.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.2.13)\n",
            "Using cached pathway-0.16.3-cp310-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.6 MB)\n",
            "Installing collected packages: pathway\n",
            "Successfully installed pathway-0.16.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XIzatGLw1pak"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}